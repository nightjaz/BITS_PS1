{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "01jY5k2qsfRJ",
        "outputId": "5d0c9e41-f308-41f6-f045-5a17f36b1616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.49)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.12)\n",
            "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.4)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.49 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.49)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.7.10)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.2)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.11)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.96.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (1.1.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.49->llama-index) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.49->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud==0.1.32 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.32)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.32->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.7.14)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.8.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.43)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.49->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.49->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.49->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.49->llama-index) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.49->llama-index) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.49->llama-index) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.49->llama-index) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.49->llama-index) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.49->llama-index) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.49->llama-index) (4.3.8)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.49->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.49->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.49->llama-index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.49->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.49->llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.43 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.43)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.49->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.49->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.49->llama-index) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.49->llama-index) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.49->llama-index) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.49->llama-index) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.49->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.49->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.43->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.49->llama-index) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.49->llama-index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.49->llama-index) (3.0.2)\n",
            "Requirement already satisfied: llama-index-embeddings-google-genai in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: google-genai<2,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-google-genai) (1.25.0)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-google-genai) (0.12.49)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (2.11.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (4.14.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (2025.3.2)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.1.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (6.0.2)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (2.0.41)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (1.3.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (4.3.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (0.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-embeddings-google-genai) (0.6.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-google-genai) (3.0.2)\n",
            "Requirement already satisfied: llama-index-llms-google-genai in /usr/local/lib/python3.11/dist-packages (0.2.5)\n",
            "Requirement already satisfied: google-genai<2,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-google-genai) (1.25.0)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.36 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-google-genai) (0.12.49)\n",
            "Requirement already satisfied: pillow>=10.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-google-genai) (11.2.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.11.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (4.14.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (2025.3.2)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.1.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (6.0.2)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (2.0.41)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (1.3.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (4.3.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (0.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.6.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index-llms-google-genai) (3.0.2)\n",
            "Requirement already satisfied: llama-index-llms-openai-like in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai-like) (0.12.49)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai-like) (0.4.7)\n",
            "Requirement already satisfied: transformers<5,>=4.37.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai-like) (4.53.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.1.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.17.2)\n",
            "Requirement already satisfied: openai<2,>=1.81.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (1.96.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like) (0.33.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (4.3.8)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers<5,>=4.37.0->llama-index-llms-openai-like) (1.1.5)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.5.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.26.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.0.2)\n",
            "Requirement already satisfied: llama-index-retrievers-bm25 in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: bm25s<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-retrievers-bm25) (0.2.13)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-retrievers-bm25) (0.12.49)\n",
            "Requirement already satisfied: pystemmer<3.0.0.0,>=2.2.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-retrievers-bm25) (2.2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.15.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2.0.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.1.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.3.8)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.0.2)\n",
            "Requirement already satisfied: ragas in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ragas) (2.0.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from ragas) (2.14.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ragas) (0.9.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.26)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.69)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.27)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.28)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ragas) (1.6.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from ragas) (1.4.4)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.11/dist-packages (from ragas) (2.11.7)\n",
            "Requirement already satisfied: openai>1 in /usr/local/lib/python3.11/dist-packages (from ragas) (1.96.1)\n",
            "Requirement already satisfied: diskcache>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from ragas) (5.6.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (4.14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (0.4.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets->ragas) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (6.0.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (0.4.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas) (1.33)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ragas) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->ragas) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->ragas) (1.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain->ragas) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain->ragas) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain->ragas) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->ragas) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->ragas) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.1.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Collecting PyPDF2\n",
            "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.96.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        " Install required packages\n",
        "!pip install llama-index\n",
        "!pip install llama-index-embeddings-google-genai\n",
        "!pip install llama-index-llms-google-genai\n",
        "!pip install llama-index-llms-openai-like\n",
        "!pip install llama-index-retrievers-bm25\n",
        "!pip install ragas\n",
        "!pip install datasets\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install PyPDF2\n",
        "!pip install rank_bm25\n",
        "!pip install openai  # For OpenRouter API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "7ZTSFm0JznYJ",
        "outputId": "67b2acec-3ca5-477e-815e-cdd1306a4f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.69)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.8-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.8\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "ade16785abbf4e2694b66745893f11a1",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.69)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Additional packages for RAGAS with Gemini\n",
        "!pip install langchain-google-genai  # For RAGAS Gemini integration\n",
        "!pip install langchain  # Core LangChain package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf0g-tnGsfRJ"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Google Drive and Colab\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "# LlamaIndex imports\n",
        "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
        "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "from llama_index.core import get_response_synthesizer\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "# RAGAS imports\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "from datasets import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPvtrPhnsfRK",
        "outputId": "b734ca43-af8e-4703-a07e-65af5f8bb1c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded successfully!\n",
            " Remember to replace OPENROUTER_API_KEY with your actual key from https://openrouter.ai/\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Configuration\n",
        "GOOGLE_API_KEY = \"Replace with your API key\"\n",
        "OPENROUTER_API_KEY = \"replace with your API key\"\n",
        "# Set up directories\n",
        "PDF_DIR = \"/content/uploaded_files\"\n",
        "DRIVE_PDF_DIR = \"/content/drive/MyDrive/uploaded_files\"  # Path to PDFs in Google Drive\n",
        "\n",
        "print(\"Configuration loaded successfully!\")\n",
        "print(\" Remember to replace OPENROUTER_API_KEY with your actual key from https://openrouter.ai/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8xlcDAjsfRK",
        "outputId": "6c0c8df9-386f-44e1-9320-9cc3657a861b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive folder not found: /content/drive/MyDrive/uploaded_files\n",
            "Please create the 'uploaded_files' folder in your Google Drive and upload PDF files there.\n",
            "Or upload PDFs directly using the cell below.\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create local directory and copy PDFs from Google Drive\n",
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "\n",
        "# Check if Google Drive folder exists\n",
        "if os.path.exists(DRIVE_PDF_DIR):\n",
        "    # Copy all PDF files from Google Drive to local directory\n",
        "    for filename in os.listdir(DRIVE_PDF_DIR):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            src = os.path.join(DRIVE_PDF_DIR, filename)\n",
        "            dst = os.path.join(PDF_DIR, filename)\n",
        "            shutil.copy2(src, dst)\n",
        "            print(f\"Copied: {filename}\")\n",
        "\n",
        "    pdf_files = [f for f in os.listdir(PDF_DIR) if f.lower().endswith('.pdf')]\n",
        "    print(f\"\\nTotal PDFs loaded: {len(pdf_files)}\")\n",
        "    for pdf in pdf_files:\n",
        "        print(f\"- {pdf}\")\n",
        "else:\n",
        "    print(f\"Google Drive folder not found: {DRIVE_PDF_DIR}\")\n",
        "    print(\"Please create the 'uploaded_files' folder in your Google Drive and upload PDF files there.\")\n",
        "    print(\"Or upload PDFs directly using the cell below.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "RCwgj_22sfRM",
        "outputId": "5489bc7a-17d8-48dd-93b4-22859715ce33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7287027e-e8cb-4742-8d91-2ee617c9c6f7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7287027e-e8cb-4742-8d91-2ee617c9c6f7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving iesc108.pdf to iesc108.pdf\n",
            "Uploaded: iesc108.pdf\n"
          ]
        }
      ],
      "source": [
        "# Alternative: Upload PDFs directly (uncomment if needed)\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    if filename.lower().endswith('.pdf'):\n",
        "        shutil.move(filename, os.path.join(PDF_DIR, filename))\n",
        "        print(f\"Uploaded: {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI3DcL85sfRM",
        "outputId": "268e681d-ea76-4068-e3a9-f34b20a6038a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 13 documents\n",
            "Created 55 chunks\n"
          ]
        }
      ],
      "source": [
        "# Load and process PDF documents\n",
        "def load_and_process_documents():\n",
        "    \"\"\"Load PDFs and create document nodes.\"\"\"\n",
        "    if not os.listdir(PDF_DIR):\n",
        "        raise ValueError(\"No PDF files found in the directory!\")\n",
        "\n",
        "    # Load documents\n",
        "    documents = SimpleDirectoryReader(PDF_DIR).load_data()\n",
        "    print(f\"Loaded {len(documents)} documents\")\n",
        "\n",
        "    # Split documents into chunks\n",
        "    # Reduced chunk size to address the warning about sequence length\n",
        "    splitter = SentenceSplitter(chunk_size=250, chunk_overlap=50) # Reduced chunk size and overlap\n",
        "    nodes = splitter.get_nodes_from_documents(documents)\n",
        "    print(f\"Created {len(nodes)} chunks\")\n",
        "\n",
        "    return documents, nodes\n",
        "\n",
        "# Load documents\n",
        "documents, nodes = load_and_process_documents()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvpdpujKsfRN",
        "outputId": "9af43bef-2e01-4e3b-ecd5-6f414857b7d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating vector index...\n",
            "Vector index created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Set up embeddings and create vector index\n",
        "embed_model = GoogleGenAIEmbedding(\n",
        "    model_name=\"models/embedding-001\",\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Create vector index\n",
        "print(\"Creating vector index...\")\n",
        "index = VectorStoreIndex(nodes)\n",
        "print(\"Vector index created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1qt_siNsfRO",
        "outputId": "01c6b5f8-0aa3-41dd-d7f6-a33c8d6ae24f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:bm25s:Building index from IDs objects\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini query engine created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Set up Gemini Query Engine\n",
        "def create_gemini_query_engine():\n",
        "    \"\"\"Create query engine using Gemini model.\"\"\"\n",
        "    bm25_retriever = BM25Retriever.from_defaults(index=index, similarity_top_k=3)\n",
        "    llm = GoogleGenAI(model=\"gemini-2.0-flash\", api_key=GOOGLE_API_KEY)\n",
        "    Settings.llm = llm\n",
        "\n",
        "    response_synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
        "    query_engine = RetrieverQueryEngine(\n",
        "        retriever=bm25_retriever,\n",
        "        response_synthesizer=response_synthesizer\n",
        "    )\n",
        "    return query_engine\n",
        "\n",
        "gemini_query_engine = create_gemini_query_engine()\n",
        "print(\"Gemini query engine created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFGk_dimsfRP",
        "outputId": "158388cf-b91e-4ff3-dec3-5c5be955e1da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:bm25s:Building index from IDs objects\n",
            "DEBUG:bm25s:Building index from IDs objects\n",
            "DEBUG:bm25s:Building index from IDs objects\n",
            "DEBUG:bm25s:Building index from IDs objects\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up OpenRouter models...\n",
            " Qwen query engine created successfully!\n",
            " Llama query engine created successfully!\n",
            " Gemma query engine created successfully!\n",
            " DeepSeek query engine created successfully!\n",
            "\n",
            " Successfully created 5 query engines:\n",
            "    Gemini\n",
            "    Qwen\n",
            "    Llama\n",
            "    Gemma\n",
            "    DeepSeek\n",
            "\n",
            " Available models for testing: ['Gemini', 'Qwen', 'Llama', 'Gemma', 'DeepSeek']\n"
          ]
        }
      ],
      "source": [
        "# Set up OpenRouter Query Engines for Multiple Models\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "\n",
        "# OpenRouter model configurations\n",
        "OPENROUTER_MODELS = {\n",
        "    \"Qwen\": \"qwen/qwen-2.5-7b-instruct\",\n",
        "    \"Llama\": \"meta-llama/llama-3.1-8b-instruct\",\n",
        "    \"Gemma\": \"google/gemma-2-9b-it\",\n",
        "    \"DeepSeek\": \"deepseek/deepseek-chat\"\n",
        "}\n",
        "\n",
        "def create_openrouter_query_engine(model_name, display_name):\n",
        "    \"\"\"Create query engine using OpenRouter API for any model.\"\"\"\n",
        "    try:\n",
        "        llm = OpenAILike(\n",
        "            model=model_name,\n",
        "            api_base=\"https://openrouter.ai/api/v1\",\n",
        "            api_key=OPENROUTER_API_KEY,\n",
        "            max_tokens=512,\n",
        "            temperature=0.7,\n",
        "            timeout=60,\n",
        "            max_retries=3\n",
        "        )\n",
        "\n",
        "        bm25_retriever = BM25Retriever.from_defaults(index=index, similarity_top_k=3)\n",
        "        response_synthesizer = get_response_synthesizer(response_mode=\"compact\", llm=llm)\n",
        "\n",
        "        query_engine = RetrieverQueryEngine(\n",
        "            retriever=bm25_retriever,\n",
        "            response_synthesizer=response_synthesizer\n",
        "        )\n",
        "\n",
        "        print(f\" {display_name} query engine created successfully!\")\n",
        "        return query_engine\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error creating {display_name} query engine: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create query engines for all models\n",
        "print(\"Setting up OpenRouter models...\")\n",
        "query_engines = {}\n",
        "\n",
        "# Add Gemini (existing)\n",
        "query_engines[\"Gemini\"] = gemini_query_engine\n",
        "\n",
        "# Add OpenRouter models\n",
        "for display_name, model_name in OPENROUTER_MODELS.items():\n",
        "    query_engines[display_name] = create_openrouter_query_engine(model_name, display_name)\n",
        "\n",
        "# Filter out None engines\n",
        "query_engines = {name: engine for name, engine in query_engines.items() if engine is not None}\n",
        "\n",
        "print(f\"\\n Successfully created {len(query_engines)} query engines:\")\n",
        "for name in query_engines.keys():\n",
        "    print(f\"    {name}\")\n",
        "\n",
        "print(f\"\\n Available models for testing: {list(query_engines.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9HPgwYyv4AN",
        "outputId": "2ac908cd-2669-4166-a045-6a45947bf248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ENHANCED PDF Q&A COMPARISON SYSTEM - READY!\n",
            "================================================================================\n",
            "\n",
            " ENHANCED FEATURES AVAILABLE:\n",
            "    Auto-generated questions for RAGAS evaluation\n",
            "    Real-time cost analysis with OpenRouter pricing\n",
            "    Speed measurement and tokens/second calculation\n",
            "    RAGAS metrics (faithfulness, relevancy, recall, precision)\n",
            "    BLEU scores and cosine similarity\n",
            "    Beautiful interactive visualizations (9 different charts)\n",
            "    Comprehensive performance comparison dashboard\n",
            "    Cost vs Quality vs Speed trade-off analysis\n",
            "    Best value recommendations\n",
            "\n",
            " MAIN FUNCTION TO RUN:\n",
            "   run_comprehensive_evaluation_with_ragas()\n",
            "\n",
            " QUICK EVALUATION FUNCTION:\n",
            "   quick_evaluate_custom_questions(['Your question 1?', 'Your question 2?'])\n",
            "\n",
            " The notebook is now streamlined and ready to use!\n",
            "    Removed redundant cells\n",
            "    Kept only essential setup (cells 0-9)\n",
            "    Enhanced evaluation system (cells 27-31)\n",
            "    All old/duplicate functionality removed\n",
            "\n",
            "  Ready to run the enhanced evaluation system!\n"
          ]
        }
      ],
      "source": [
        "#  READY TO USE ENHANCED EVALUATION SYSTEM!\n",
        "\n",
        "print(\" ENHANCED PDF Q&A COMPARISON SYSTEM - READY!\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "print(\" ENHANCED FEATURES AVAILABLE:\")\n",
        "print(\"    Auto-generated questions for RAGAS evaluation\")\n",
        "print(\"    Real-time cost analysis with OpenRouter pricing\")\n",
        "print(\"    Speed measurement and tokens/second calculation\")\n",
        "print(\"    RAGAS metrics (faithfulness, relevancy, recall, precision)\")\n",
        "print(\"    BLEU scores and cosine similarity\")\n",
        "print(\"    Beautiful interactive visualizations (9 different charts)\")\n",
        "print(\"    Comprehensive performance comparison dashboard\")\n",
        "print(\"    Cost vs Quality vs Speed trade-off analysis\")\n",
        "print(\"    Best value recommendations\")\n",
        "print()\n",
        "print(\" MAIN FUNCTION TO RUN:\")\n",
        "print(\"   run_comprehensive_evaluation_with_ragas()\")\n",
        "print()\n",
        "print(\" QUICK EVALUATION FUNCTION:\")\n",
        "print(\"   quick_evaluate_custom_questions(['Your question 1?', 'Your question 2?'])\")\n",
        "print()\n",
        "print(\" The notebook is now streamlined and ready to use!\")\n",
        "print(\"    Removed redundant cells\")\n",
        "print(\"    Kept only essential setup (cells 0-9)\")\n",
        "print(\"    Enhanced evaluation system (cells 27-31)\")\n",
        "print(\"    All old/duplicate functionality removed\")\n",
        "print()\n",
        "print(\"  Ready to run the enhanced evaluation system!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2niWx0-jv4AN",
        "outputId": "238c6f03-8827-45c4-e67f-485b061ccea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Cost Analysis & Performance Tracking System Initialized!\n",
            " Features:\n",
            "    Real-time cost calculation based on OpenRouter pricing\n",
            "    Speed measurement (response time, tokens/second)\n",
            "    Token usage tracking\n",
            "    Error rate monitoring\n",
            "    Provider comparison\n",
            " Ready to track model performance!\n"
          ]
        }
      ],
      "source": [
        "#  COST ANALYSIS & SPEED MEASUREMENT SYSTEM\n",
        "# Enhanced version with cost tracking, speed measurement, and comprehensive comparison\n",
        "\n",
        "import time\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple\n",
        "import json\n",
        "\n",
        "# OpenRouter model pricing (per 1M tokens) - Updated 2024 pricing\n",
        "MODEL_PRICING = {\n",
        "    \"qwen/qwen-2.5-7b-instruct\": {\n",
        "        \"input_cost\": 0.20,\n",
        "        \"output_cost\": 0.20,\n",
        "        \"provider\": \"Qwen/Alibaba\"\n",
        "    },\n",
        "    \"meta-llama/llama-3.1-8b-instruct\": {\n",
        "        \"input_cost\": 0.59,\n",
        "        \"output_cost\": 0.59,\n",
        "        \"provider\": \"Meta\"\n",
        "    },\n",
        "    \"google/gemma-2-9b-it\": {\n",
        "        \"input_cost\": 0.20,\n",
        "        \"output_cost\": 0.20,\n",
        "        \"provider\": \"Google\"\n",
        "    },\n",
        "    \"deepseek/deepseek-chat\": {\n",
        "        \"input_cost\": 0.14,\n",
        "        \"output_cost\": 0.28,\n",
        "        \"provider\": \"DeepSeek\"\n",
        "    },\n",
        "    \"sarvamai/sarvam-m\": {\n",
        "        \"input_cost\": 0.10,  # Estimated\n",
        "        \"output_cost\": 0.15,  # Estimated\n",
        "        \"provider\": \"Sarvam\"\n",
        "    },\n",
        "    \"google/gemini-2.0-flash\": {\n",
        "        \"input_cost\": 1.25,\n",
        "        \"output_cost\": 5.00,\n",
        "        \"provider\": \"Google\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def count_tokens_estimate(text: str) -> int:\n",
        "    \"\"\"Estimate token count (rough approximation: 1 token  0.75 words).\"\"\"\n",
        "    return len(text.split()) // 0.75 if text else 0\n",
        "\n",
        "def calculate_cost(input_tokens: int, output_tokens: int, model_key: str) -> float:\n",
        "    \"\"\"Calculate cost in USD for a model based on token usage.\"\"\"\n",
        "    if model_key not in MODEL_PRICING:\n",
        "        return 0.0\n",
        "\n",
        "    pricing = MODEL_PRICING[model_key]\n",
        "    input_cost = (input_tokens / 1_000_000) * pricing[\"input_cost\"]\n",
        "    output_cost = (output_tokens / 1_000_000) * pricing[\"output_cost\"]\n",
        "    return input_cost + output_cost\n",
        "\n",
        "class ModelPerformanceTracker:\n",
        "    \"\"\"Track performance metrics including cost, speed, and quality for each model.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metrics = {}\n",
        "        self.session_start = datetime.now()\n",
        "\n",
        "    def start_query(self, model_name: str, question: str):\n",
        "        \"\"\"Start tracking a query.\"\"\"\n",
        "        if model_name not in self.metrics:\n",
        "            self.metrics[model_name] = {\n",
        "                \"queries\": [],\n",
        "                \"total_cost\": 0.0,\n",
        "                \"total_time\": 0.0,\n",
        "                \"total_input_tokens\": 0,\n",
        "                \"total_output_tokens\": 0,\n",
        "                \"errors\": 0\n",
        "            }\n",
        "\n",
        "        return time.time()\n",
        "\n",
        "    def end_query(self, model_name: str, start_time: float, question: str,\n",
        "                  answer: str, context_texts: List[str] = None, error: bool = False):\n",
        "        \"\"\"End tracking a query and record metrics.\"\"\"\n",
        "        end_time = time.time()\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        if error:\n",
        "            self.metrics[model_name][\"errors\"] += 1\n",
        "            return\n",
        "\n",
        "        # Estimate tokens\n",
        "        input_tokens = count_tokens_estimate(question)\n",
        "        if context_texts:\n",
        "            for ctx in context_texts:\n",
        "                input_tokens += count_tokens_estimate(ctx)\n",
        "\n",
        "        output_tokens = count_tokens_estimate(answer)\n",
        "\n",
        "        # Calculate cost\n",
        "        model_key = self._get_model_key(model_name)\n",
        "        cost = calculate_cost(input_tokens, output_tokens, model_key)\n",
        "\n",
        "        # Record metrics\n",
        "        query_data = {\n",
        "            \"question\": question,\n",
        "            \"answer\": answer,\n",
        "            \"duration\": duration,\n",
        "            \"input_tokens\": input_tokens,\n",
        "            \"output_tokens\": output_tokens,\n",
        "            \"cost\": cost,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        self.metrics[model_name][\"queries\"].append(query_data)\n",
        "        self.metrics[model_name][\"total_cost\"] += cost\n",
        "        self.metrics[model_name][\"total_time\"] += duration\n",
        "        self.metrics[model_name][\"total_input_tokens\"] += input_tokens\n",
        "        self.metrics[model_name][\"total_output_tokens\"] += output_tokens\n",
        "\n",
        "    def _get_model_key(self, model_name: str) -> str:\n",
        "        \"\"\"Map display name to model key for pricing.\"\"\"\n",
        "        mapping = {\n",
        "            \"Qwen\": \"qwen/qwen-2.5-7b-instruct\",\n",
        "            \"Llama\": \"meta-llama/llama-3.1-8b-instruct\",\n",
        "            \"Gemma\": \"google/gemma-2-9b-it\",\n",
        "            \"DeepSeek\": \"deepseek/deepseek-chat\",\n",
        "            \"Sarvam\": \"sarvamai/sarvam-m\",\n",
        "            \"Gemini\": \"google/gemini-2.0-flash\"\n",
        "        }\n",
        "        return mapping.get(model_name, \"unknown\")\n",
        "\n",
        "    def get_summary(self) -> Dict:\n",
        "        \"\"\"Get comprehensive summary of all metrics.\"\"\"\n",
        "        summary = {}\n",
        "\n",
        "        for model_name, data in self.metrics.items():\n",
        "            if len(data[\"queries\"]) > 0:\n",
        "                avg_duration = data[\"total_time\"] / len(data[\"queries\"])\n",
        "                avg_cost_per_query = data[\"total_cost\"] / len(data[\"queries\"])\n",
        "                tokens_per_second = (data[\"total_input_tokens\"] + data[\"total_output_tokens\"]) / data[\"total_time\"] if data[\"total_time\"] > 0 else 0\n",
        "\n",
        "                summary[model_name] = {\n",
        "                    \"total_queries\": len(data[\"queries\"]),\n",
        "                    \"total_cost_usd\": data[\"total_cost\"],\n",
        "                    \"total_time_seconds\": data[\"total_time\"],\n",
        "                    \"avg_response_time\": avg_duration,\n",
        "                    \"avg_cost_per_query\": avg_cost_per_query,\n",
        "                    \"total_input_tokens\": data[\"total_input_tokens\"],\n",
        "                    \"total_output_tokens\": data[\"total_output_tokens\"],\n",
        "                    \"tokens_per_second\": tokens_per_second,\n",
        "                    \"error_rate\": data[\"errors\"] / (len(data[\"queries\"]) + data[\"errors\"]) if (len(data[\"queries\"]) + data[\"errors\"]) > 0 else 0,\n",
        "                    \"provider\": MODEL_PRICING.get(self._get_model_key(model_name), {}).get(\"provider\", \"Unknown\")\n",
        "                }\n",
        "\n",
        "        return summary\n",
        "\n",
        "# Initialize global performance tracker\n",
        "performance_tracker = ModelPerformanceTracker()\n",
        "\n",
        "print(\" Cost Analysis & Performance Tracking System Initialized!\")\n",
        "print(\" Features:\")\n",
        "print(\"    Real-time cost calculation based on OpenRouter pricing\")\n",
        "print(\"    Speed measurement (response time, tokens/second)\")\n",
        "print(\"    Token usage tracking\")\n",
        "print(\"    Error rate monitoring\")\n",
        "print(\"    Provider comparison\")\n",
        "print(\" Ready to track model performance!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wfvkorvv4AP",
        "outputId": "ee375c80-270d-439e-f7f2-f22a266f738a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Enhanced model answer function and RAGAS question generator ready!\n",
            " New features:\n",
            "    Integrated performance tracking\n",
            "    Cost calculation during query execution\n",
            "    Speed measurement for each model\n",
            "    Enhanced question generation for RAGAS\n",
            "    Real-time metrics display\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Model Answer Function with Performance Tracking\n",
        "def get_model_answers_with_tracking(questions: List[str], use_generated_questions: bool = False) -> Dict:\n",
        "    \"\"\"Get answers from all available models with comprehensive performance tracking.\"\"\"\n",
        "\n",
        "    # Include Gemini temporarily for getting baseline responses\n",
        "    all_engines = query_engines.copy()\n",
        "    if \"Gemini\" not in all_engines:\n",
        "        all_engines[\"Gemini\"] = gemini_query_engine\n",
        "\n",
        "    results = {\n",
        "        'questions': questions,\n",
        "        'model_answers': {},\n",
        "        'model_contexts': {},\n",
        "        'performance_metrics': {}\n",
        "    }\n",
        "\n",
        "    # Initialize results for each model\n",
        "    for model_name in all_engines.keys():\n",
        "        results['model_answers'][model_name] = []\n",
        "        results['model_contexts'][model_name] = []\n",
        "\n",
        "    print(f\" Getting answers from {len(all_engines)} models with performance tracking...\")\n",
        "    print(f\" Models: {list(all_engines.keys())}\")\n",
        "    print(f\" Tracking: Cost, Speed, Token Usage, Error Rate\")\n",
        "\n",
        "    for i, question in enumerate(questions):\n",
        "        print(f\"\\n Processing question {i+1}/{len(questions)}: {question[:60]}...\")\n",
        "\n",
        "        for model_name, query_engine in all_engines.items():\n",
        "            # Start performance tracking\n",
        "            start_time = performance_tracker.start_query(model_name, question)\n",
        "\n",
        "            try:\n",
        "                print(f\"   Getting {model_name} response...\")\n",
        "\n",
        "                # Special handling for Gemini\n",
        "                if model_name == \"Gemini\":\n",
        "                    Settings.llm = GoogleGenAI(model=\"gemini-2.0-flash\", api_key=GOOGLE_API_KEY)\n",
        "\n",
        "                response = query_engine.query(question)\n",
        "                answer = response.response if hasattr(response, \"response\") else str(response)\n",
        "                context = [node.text for node in response.source_nodes] if hasattr(response, \"source_nodes\") else []\n",
        "\n",
        "                # Handle empty responses\n",
        "                if not answer or answer.strip() == \"\":\n",
        "                    answer = f\"No response generated by {model_name}\"\n",
        "\n",
        "                results['model_answers'][model_name].append(answer)\n",
        "                results['model_contexts'][model_name].append(context)\n",
        "\n",
        "                # End performance tracking\n",
        "                performance_tracker.end_query(model_name, start_time, question, answer, context)\n",
        "\n",
        "                print(f\"      {model_name}: {len(answer)} chars, {len(context)} contexts\")\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"Error: {str(e)[:100]}...\"\n",
        "                print(f\"      {model_name}: {error_msg}\")\n",
        "                results['model_answers'][model_name].append(f\"Error: Unable to generate response - {str(e)}\")\n",
        "                results['model_contexts'][model_name].append([])\n",
        "\n",
        "                # Record error in tracking\n",
        "                performance_tracker.end_query(model_name, start_time, question, \"\", [], error=True)\n",
        "\n",
        "    # Get performance summary\n",
        "    results['performance_metrics'] = performance_tracker.get_summary()\n",
        "\n",
        "    print(f\"\\n Completed getting answers from all {len(all_engines)} models!\")\n",
        "    print(\"\\n COST & PERFORMANCE SUMMARY:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for model_name, metrics in results['performance_metrics'].items():\n",
        "        print(f\"{model_name}:\")\n",
        "        print(f\"   Total Cost: ${metrics['total_cost_usd']:.6f}\")\n",
        "        print(f\"    Avg Response Time: {metrics['avg_response_time']:.2f}s\")\n",
        "        print(f\"   Tokens/Second: {metrics['tokens_per_second']:.1f}\")\n",
        "        print(f\"   Success Rate: {(1-metrics['error_rate'])*100:.1f}%\")\n",
        "        print()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Enhanced Question Generation for RAGAS\n",
        "def generate_comprehensive_questions_for_ragas(num_questions: int = 10) -> List[str]:\n",
        "    \"\"\"Generate comprehensive questions specifically designed for RAGAS evaluation.\"\"\"\n",
        "\n",
        "    # Create sample content for question generation\n",
        "    sample_content = \"\"\n",
        "    if documents:\n",
        "        for i, doc in enumerate(documents[:3]):\n",
        "            content_preview = doc.text[:1500]  # More content for better questions\n",
        "            sample_content += f\"Document {i+1} excerpt: {content_preview}\\n\\n\"\n",
        "\n",
        "    question_generation_prompt = f\"\"\"\n",
        "    Based on the following document content, generate {num_questions} diverse evaluation questions that are specifically designed to test different aspects of a question-answering system for RAGAS evaluation.\n",
        "\n",
        "    Generate questions that test these specific capabilities:\n",
        "    1. FAITHFULNESS - Questions where answers can be verified against source content\n",
        "    2. ANSWER RELEVANCY - Questions that require directly relevant responses\n",
        "    3. CONTEXT RECALL - Questions that test if the system retrieves all relevant information\n",
        "    4. CONTEXT PRECISION - Questions that test if retrieved information is focused and relevant\n",
        "\n",
        "    Question types to include:\n",
        "    - Factual questions (asking for specific information present in the text)\n",
        "    - Analytical questions (requiring interpretation of information)\n",
        "    - Summary questions (asking for main points or conclusions)\n",
        "    - Comparative questions (comparing different concepts or ideas)\n",
        "    - Inference questions (requiring reading between the lines)\n",
        "    - Detail-oriented questions (focusing on specific facts or figures)\n",
        "\n",
        "    Document Content:\n",
        "    {sample_content}\n",
        "\n",
        "    Requirements:\n",
        "    - Generate exactly {num_questions} questions\n",
        "    - Each question should be clear and answerable from the document content\n",
        "    - Questions should vary in complexity and type\n",
        "    - Format: One question per line, ending with '?'\n",
        "    - No numbering or bullet points\n",
        "    - Make questions challenging but fair for model evaluation\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        print(\" Generating comprehensive questions for RAGAS evaluation...\")\n",
        "\n",
        "        llm = GoogleGenAI(model=\"gemini-2.0-flash\", api_key=GOOGLE_API_KEY, temperature=0.7)\n",
        "        response = llm.complete(question_generation_prompt)\n",
        "\n",
        "        generated_text = response.text if hasattr(response, 'text') else str(response)\n",
        "        questions = [q.strip() for q in generated_text.split('\\n') if q.strip() and not q.strip().isdigit()]\n",
        "\n",
        "        # Clean and validate questions\n",
        "        valid_questions = []\n",
        "        for q in questions:\n",
        "            q = q.lstrip('0123456789.- ').strip()\n",
        "            if q and ('?' in q or q.endswith('.')):\n",
        "                if not q.endswith('?'):\n",
        "                    q = q.rstrip('.') + '?'\n",
        "                valid_questions.append(q)\n",
        "\n",
        "        # Ensure we have the requested number\n",
        "        valid_questions = valid_questions[:num_questions]\n",
        "\n",
        "        if len(valid_questions) < num_questions:\n",
        "            print(f\" Generated {len(valid_questions)} questions, requested {num_questions}\")\n",
        "            # Add fallback questions if needed\n",
        "            fallback_questions = [\n",
        "                \"What is the main topic discussed in this document?\",\n",
        "                \"What are the key findings or conclusions presented?\",\n",
        "                \"What methodology or approach is described in the text?\",\n",
        "                \"What are the most important details mentioned?\",\n",
        "                \"How do the different concepts in the document relate to each other?\",\n",
        "                \"What evidence is provided to support the main claims?\",\n",
        "                \"What future work or recommendations are suggested?\",\n",
        "                \"What are the limitations or challenges mentioned?\",\n",
        "                \"What specific examples or case studies are provided?\",\n",
        "                \"What background information is essential to understanding this topic?\"\n",
        "            ]\n",
        "\n",
        "            while len(valid_questions) < num_questions and fallback_questions:\n",
        "                valid_questions.append(fallback_questions.pop(0))\n",
        "\n",
        "        print(f\" Successfully generated {len(valid_questions)} questions for RAGAS evaluation!\")\n",
        "        return valid_questions\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error generating questions: {e}\")\n",
        "        print(\" Using fallback questions...\")\n",
        "\n",
        "        fallback_questions = [\n",
        "            \"What is the main topic discussed in this document?\",\n",
        "            \"What are the key findings or conclusions presented?\",\n",
        "            \"What methodology or approach is described in the text?\",\n",
        "            \"What are the most important details mentioned?\",\n",
        "            \"How do the different concepts in the document relate to each other?\",\n",
        "            \"What evidence is provided to support the main claims?\",\n",
        "            \"What future work or recommendations are suggested?\",\n",
        "            \"What are the limitations or challenges mentioned?\",\n",
        "            \"What specific examples or case studies are provided?\",\n",
        "            \"What background information is essential to understanding this topic?\"\n",
        "        ]\n",
        "        return fallback_questions[:num_questions]\n",
        "\n",
        "print(\" Enhanced model answer function and RAGAS question generator ready!\")\n",
        "print(\" New features:\")\n",
        "print(\"    Integrated performance tracking\")\n",
        "print(\"    Cost calculation during query execution\")\n",
        "print(\"    Speed measurement for each model\")\n",
        "print(\"    Enhanced question generation for RAGAS\")\n",
        "print(\"    Real-time metrics display\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHUNOPx7v4AQ",
        "outputId": "de05e946-b6b3-4c13-d06d-c5ed54cc578c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " READY TO RUN COMPREHENSIVE EVALUATION!\n",
            "This will:\n",
            "   1. Generate optimized questions for RAGAS\n",
            "   2. Get answers from all models with cost/speed tracking\n",
            "   3. Run RAGAS evaluation (faithfulness, relevancy, recall, precision)\n",
            "   4. Calculate BLEU scores and cosine similarity\n",
            "   5. Create beautiful interactive visualizations\n",
            "   6. Provide comprehensive cost and performance analysis\n",
            "\n",
            " Starting evaluation...\n"
          ]
        }
      ],
      "source": [
        "#  COMPREHENSIVE EVALUATION WITH AUTO-GENERATED QUESTIONS AND FULL TRACKING\n",
        "\n",
        "def run_comprehensive_evaluation_with_ragas():\n",
        "    \"\"\"Run complete evaluation using auto-generated questions designed for RAGAS.\"\"\"\n",
        "\n",
        "    print(\" STARTING COMPREHENSIVE EVALUATION\")\n",
        "    print(\"=\"*80)\n",
        "    print(\" Features included:\")\n",
        "    print(\"    Auto-generated questions for RAGAS evaluation\")\n",
        "    print(\"    Real-time cost tracking\")\n",
        "    print(\"    Speed measurement\")\n",
        "    print(\"    RAGAS metrics (faithfulness, relevancy, recall, precision)\")\n",
        "    print(\"    BLEU scores and cosine similarity\")\n",
        "    print(\"    Beautiful interactive visualizations\")\n",
        "    print(\"    Comprehensive performance comparison\")\n",
        "    print()\n",
        "\n",
        "    # Step 1: Generate questions specifically for RAGAS\n",
        "    print(\" Step 1: Generating Questions for RAGAS Evaluation\")\n",
        "    ragas_questions = generate_comprehensive_questions_for_ragas(8)\n",
        "\n",
        "    print(\" Generated Questions for RAGAS:\")\n",
        "    for i, q in enumerate(ragas_questions, 1):\n",
        "        print(f\"   {i}. {q}\")\n",
        "    print()\n",
        "\n",
        "    # Step 2: Get model answers with performance tracking\n",
        "    print(\" Step 2: Getting Model Answers with Performance Tracking\")\n",
        "    model_results_tracked = get_model_answers_with_tracking(ragas_questions)\n",
        "\n",
        "    # Step 3: Prepare ground truth using Gemini (exclude from scoring)\n",
        "    print(\" Step 3: Setting Up Ground Truth and RAGAS Evaluation\")\n",
        "    ground_truth_answers = model_results_tracked['model_answers']['Gemini'].copy()\n",
        "\n",
        "    # Remove Gemini from evaluation to avoid self-scoring\n",
        "    models_to_evaluate = {k: v for k, v in model_results_tracked['model_answers'].items() if k != 'Gemini'}\n",
        "    model_contexts_to_evaluate = {k: v for k, v in model_results_tracked['model_contexts'].items() if k != 'Gemini'}\n",
        "\n",
        "    print(f\" Models to evaluate with RAGAS: {list(models_to_evaluate.keys())}\")\n",
        "    print(f\" Ground truth provider: Gemini (excluded from scoring)\")\n",
        "    print()\n",
        "\n",
        "    # Step 4: Run RAGAS evaluation\n",
        "    print(\" Step 4: Running RAGAS Evaluation\")\n",
        "    ragas_datasets = {}\n",
        "    ragas_results = {}\n",
        "\n",
        "    for model_name in models_to_evaluate.keys():\n",
        "        print(f\" Preparing RAGAS dataset for {model_name}...\")\n",
        "        model_data = {\n",
        "            'question': ragas_questions,\n",
        "            'answer': models_to_evaluate[model_name],\n",
        "            'contexts': model_contexts_to_evaluate[model_name],\n",
        "            'ground_truth': ground_truth_answers\n",
        "        }\n",
        "        ragas_datasets[model_name] = Dataset.from_dict(model_data)\n",
        "\n",
        "    # Run RAGAS evaluation for each model\n",
        "    for model_name, dataset in ragas_datasets.items():\n",
        "        try:\n",
        "            print(f\" Running RAGAS evaluation for {model_name}...\")\n",
        "            result = evaluate_with_ragas(dataset, model_name)\n",
        "            ragas_results[model_name] = result\n",
        "        except Exception as e:\n",
        "            print(f\" RAGAS evaluation failed for {model_name}: {e}\")\n",
        "            ragas_results[model_name] = None\n",
        "\n",
        "    # Step 5: Run enhanced evaluation (BLEU, cosine similarity)\n",
        "    print(\" Step 5: Running Enhanced Evaluation (BLEU, Cosine Similarity)\")\n",
        "    temp_results = {\n",
        "        'questions': ragas_questions,\n",
        "        'model_answers': models_to_evaluate,\n",
        "        'model_contexts': model_contexts_to_evaluate\n",
        "    }\n",
        "    enhanced_results = enhanced_model_evaluation(temp_results, ground_truth_answers)\n",
        "\n",
        "    # Step 6: Create comprehensive results combining all metrics\n",
        "    print(\" Step 6: Creating Comprehensive Results\")\n",
        "    comprehensive_results = create_comprehensive_results(\n",
        "        ragas_results,\n",
        "        enhanced_results,\n",
        "        model_results_tracked['performance_metrics']\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'questions': ragas_questions,\n",
        "        'model_answers': model_results_tracked['model_answers'],\n",
        "        'model_contexts': model_results_tracked['model_contexts'],\n",
        "        'performance_metrics': model_results_tracked['performance_metrics'],\n",
        "        'ragas_results': ragas_results,\n",
        "        'enhanced_results': enhanced_results,\n",
        "        'comprehensive_results': comprehensive_results,\n",
        "        'ground_truth': ground_truth_answers\n",
        "    }\n",
        "\n",
        "def create_comprehensive_results(ragas_results, enhanced_results, performance_metrics):\n",
        "    \"\"\"Combine all evaluation results into a comprehensive summary.\"\"\"\n",
        "\n",
        "    comprehensive = {}\n",
        "\n",
        "    # Get all models (excluding Gemini which was used as baseline)\n",
        "    all_models = set()\n",
        "    if ragas_results:\n",
        "        all_models.update(ragas_results.keys())\n",
        "    if enhanced_results:\n",
        "        all_models.update(enhanced_results.keys())\n",
        "    if performance_metrics:\n",
        "        all_models.update(performance_metrics.keys())\n",
        "\n",
        "    # Remove Gemini from final results\n",
        "    all_models.discard('Gemini')\n",
        "\n",
        "    for model in all_models:\n",
        "        comprehensive[model] = {\n",
        "            'model_name': model,\n",
        "            'provider': performance_metrics.get(model, {}).get('provider', 'Unknown')\n",
        "        }\n",
        "\n",
        "        # Add RAGAS metrics\n",
        "        if model in ragas_results and ragas_results[model]:\n",
        "            try:\n",
        "                ragas_df = ragas_results[model].to_pandas()\n",
        "                comprehensive[model].update({\n",
        "                    'faithfulness': ragas_df['faithfulness'].mean() if 'faithfulness' in ragas_df.columns else 0,\n",
        "                    'answer_relevancy': ragas_df['answer_relevancy'].mean() if 'answer_relevancy' in ragas_df.columns else 0,\n",
        "                    'context_recall': ragas_df['context_recall'].mean() if 'context_recall' in ragas_df.columns else 0,\n",
        "                    'context_precision': ragas_df['context_precision'].mean() if 'context_precision' in ragas_df.columns else 0,\n",
        "                })\n",
        "            except:\n",
        "                comprehensive[model].update({\n",
        "                    'faithfulness': 0, 'answer_relevancy': 0, 'context_recall': 0, 'context_precision': 0\n",
        "                })\n",
        "        else:\n",
        "            comprehensive[model].update({\n",
        "                'faithfulness': 0, 'answer_relevancy': 0, 'context_recall': 0, 'context_precision': 0\n",
        "            })\n",
        "\n",
        "        # Add enhanced metrics\n",
        "        if model in enhanced_results:\n",
        "            comprehensive[model].update({\n",
        "                'bleu_score': enhanced_results[model]['avg_bleu_score'],\n",
        "                'cosine_similarity': enhanced_results[model]['avg_cosine_similarity'],\n",
        "                'avg_word_count': enhanced_results[model]['avg_word_count'],\n",
        "                'avg_sentence_count': enhanced_results[model]['avg_sentence_count']\n",
        "            })\n",
        "        else:\n",
        "            comprehensive[model].update({\n",
        "                'bleu_score': 0, 'cosine_similarity': 0, 'avg_word_count': 0, 'avg_sentence_count': 0\n",
        "            })\n",
        "\n",
        "        # Add performance metrics\n",
        "        if model in performance_metrics:\n",
        "            comprehensive[model].update({\n",
        "                'total_cost_usd': performance_metrics[model]['total_cost_usd'],\n",
        "                'avg_response_time': performance_metrics[model]['avg_response_time'],\n",
        "                'tokens_per_second': performance_metrics[model]['tokens_per_second'],\n",
        "                'success_rate': (1 - performance_metrics[model]['error_rate']) * 100,\n",
        "                'total_tokens': performance_metrics[model]['total_input_tokens'] + performance_metrics[model]['total_output_tokens']\n",
        "            })\n",
        "        else:\n",
        "            comprehensive[model].update({\n",
        "                'total_cost_usd': 0, 'avg_response_time': 0, 'tokens_per_second': 0, 'success_rate': 100, 'total_tokens': 0\n",
        "            })\n",
        "\n",
        "    return comprehensive\n",
        "\n",
        "# Run the comprehensive evaluation\n",
        "print(\" READY TO RUN COMPREHENSIVE EVALUATION!\")\n",
        "print(\"This will:\")\n",
        "print(\"   1. Generate optimized questions for RAGAS\")\n",
        "print(\"   2. Get answers from all models with cost/speed tracking\")\n",
        "print(\"   3. Run RAGAS evaluation (faithfulness, relevancy, recall, precision)\")\n",
        "print(\"   4. Calculate BLEU scores and cosine similarity\")\n",
        "print(\"   5. Create beautiful interactive visualizations\")\n",
        "print(\"   6. Provide comprehensive cost and performance analysis\")\n",
        "print(\"\\n Starting evaluation...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UWKDXaVv4AQ",
        "outputId": "cb6ca60a-2e51-4307-a50c-d68ac1e34341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Enhanced visualization system ready!\n",
            " Features:\n",
            "    Ultimate performance dashboard (9 different charts)\n",
            "    Detailed cost breakdown analysis\n",
            "    Comprehensive summary tables\n",
            "    Best performer identification\n",
            "    Interactive visualizations\n",
            " Ready to create beautiful insights!\n"
          ]
        }
      ],
      "source": [
        "#  ENHANCED VISUALIZATION SYSTEM WITH COST AND SPEED ANALYSIS\n",
        "\n",
        "def create_ultimate_performance_dashboard(comprehensive_results):\n",
        "    \"\"\"Create the ultimate performance dashboard with all metrics.\"\"\"\n",
        "\n",
        "    models = list(comprehensive_results.keys())\n",
        "\n",
        "    # Create a large subplot layout\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=3,\n",
        "        subplot_titles=(\n",
        "            ' Cost Analysis', ' Speed Performance', ' RAGAS Quality Metrics',\n",
        "            ' BLEU & Cosine Similarity', ' Response Characteristics', ' Overall Rankings',\n",
        "            ' Cost vs Quality Trade-off', ' Speed vs Quality Trade-off', ' Best Value Analysis'\n",
        "        ),\n",
        "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"scatterpolar\"}],\n",
        "               [{\"type\": \"bar\"}, {\"type\": \"scatter\"}, {\"type\": \"bar\"}],\n",
        "               [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
        "    )\n",
        "\n",
        "    # Model colors\n",
        "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#6C5CE7']\n",
        "    model_colors = {model: colors[i % len(colors)] for i, model in enumerate(models)}\n",
        "\n",
        "    # 1. Cost Analysis\n",
        "    costs = [comprehensive_results[model]['total_cost_usd'] for model in models]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=costs, name='Cost (USD)',\n",
        "               marker_color=[model_colors[m] for m in models],\n",
        "               text=[f'${cost:.6f}' for cost in costs], textposition='auto'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # 2. Speed Performance\n",
        "    response_times = [comprehensive_results[model]['avg_response_time'] for model in models]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=response_times, name='Response Time (s)',\n",
        "               marker_color=[model_colors[m] for m in models],\n",
        "               text=[f'{time:.2f}s' for time in response_times], textposition='auto'),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # 3. RAGAS Quality Metrics (Radar Chart)\n",
        "    ragas_metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']\n",
        "\n",
        "    for i, model in enumerate(models[:3]):  # Show top 3 models to avoid clutter\n",
        "        values = [comprehensive_results[model][metric] for metric in ragas_metrics]\n",
        "        fig.add_trace(\n",
        "            go.Scatterpolar(\n",
        "                r=values,\n",
        "                theta=ragas_metrics,\n",
        "                fill='toself',\n",
        "                name=model,\n",
        "                line_color=model_colors[model]\n",
        "            ),\n",
        "            row=1, col=3\n",
        "        )\n",
        "\n",
        "    # 4. BLEU & Cosine Similarity\n",
        "    bleu_scores = [comprehensive_results[model]['bleu_score'] for model in models]\n",
        "    cosine_scores = [comprehensive_results[model]['cosine_similarity'] for model in models]\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=bleu_scores, name='BLEU Score',\n",
        "               marker_color='lightblue', opacity=0.7),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=cosine_scores, name='Cosine Similarity',\n",
        "               marker_color='lightcoral', opacity=0.7, yaxis='y2'),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # 5. Response Characteristics (Length vs Quality)\n",
        "    word_counts = [comprehensive_results[model]['avg_word_count'] for model in models]\n",
        "    avg_quality = [(comprehensive_results[model]['faithfulness'] +\n",
        "                   comprehensive_results[model]['answer_relevancy']) / 2 for model in models]\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=word_counts, y=avg_quality, mode='markers+text',\n",
        "                  text=models, textposition='top center',\n",
        "                  marker=dict(size=12, color=[model_colors[m] for m in models]),\n",
        "                  name='Length vs Quality'),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "    # 6. Overall Rankings (Combined Score)\n",
        "    overall_scores = []\n",
        "    for model in models:\n",
        "        # Weighted scoring: Quality (60%), Speed (20%), Cost (20%)\n",
        "        quality_score = (comprehensive_results[model]['faithfulness'] +\n",
        "                        comprehensive_results[model]['answer_relevancy'] +\n",
        "                        comprehensive_results[model]['bleu_score'] * 10 +  # Scale BLEU\n",
        "                        comprehensive_results[model]['cosine_similarity']) / 4\n",
        "\n",
        "        speed_score = 1 / (comprehensive_results[model]['avg_response_time'] + 0.1)  # Faster = higher score\n",
        "        cost_score = 1 / (comprehensive_results[model]['total_cost_usd'] * 1000 + 0.01)  # Cheaper = higher score\n",
        "\n",
        "        overall = quality_score * 0.6 + speed_score * 0.2 + cost_score * 0.2\n",
        "        overall_scores.append(overall)\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=overall_scores, name='Overall Score',\n",
        "               marker_color=[model_colors[m] for m in models],\n",
        "               text=[f'{score:.3f}' for score in overall_scores], textposition='auto'),\n",
        "        row=2, col=3\n",
        "    )\n",
        "\n",
        "    # 7. Cost vs Quality Trade-off\n",
        "    quality_scores = avg_quality\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=costs, y=quality_scores, mode='markers+text',\n",
        "                  text=models, textposition='top center',\n",
        "                  marker=dict(size=15, color=[model_colors[m] for m in models]),\n",
        "                  name='Cost vs Quality'),\n",
        "        row=3, col=1\n",
        "    )\n",
        "\n",
        "    # 8. Speed vs Quality Trade-off\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=response_times, y=quality_scores, mode='markers+text',\n",
        "                  text=models, textposition='top center',\n",
        "                  marker=dict(size=15, color=[model_colors[m] for m in models]),\n",
        "                  name='Speed vs Quality'),\n",
        "        row=3, col=2\n",
        "    )\n",
        "\n",
        "    # 9. Best Value Analysis (Quality per Dollar)\n",
        "    value_scores = [q / (c * 1000 + 0.001) for q, c in zip(quality_scores, costs)]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=value_scores, name='Value Score (Quality/Cost)',\n",
        "               marker_color=[model_colors[m] for m in models],\n",
        "               text=[f'{score:.1f}' for score in value_scores], textposition='auto'),\n",
        "        row=3, col=3\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        height=1200,\n",
        "        title_text=\" Ultimate Model Performance Dashboard - Cost, Speed & Quality Analysis\",\n",
        "        title_x=0.5,\n",
        "        title_font_size=24,\n",
        "        showlegend=False\n",
        "    )\n",
        "\n",
        "    # Update axes labels\n",
        "    fig.update_xaxes(title_text=\"Models\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Cost (USD)\", row=1, col=1)\n",
        "    fig.update_xaxes(title_text=\"Models\", row=1, col=2)\n",
        "    fig.update_yaxes(title_text=\"Response Time (s)\", row=1, col=2)\n",
        "    fig.update_xaxes(title_text=\"Word Count\", row=2, col=2)\n",
        "    fig.update_yaxes(title_text=\"Quality Score\", row=2, col=2)\n",
        "    fig.update_xaxes(title_text=\"Cost (USD)\", row=3, col=1)\n",
        "    fig.update_yaxes(title_text=\"Quality Score\", row=3, col=1)\n",
        "    fig.update_xaxes(title_text=\"Response Time (s)\", row=3, col=2)\n",
        "    fig.update_yaxes(title_text=\"Quality Score\", row=3, col=2)\n",
        "\n",
        "    return fig\n",
        "\n",
        "def create_cost_breakdown_analysis(comprehensive_results):\n",
        "    \"\"\"Create detailed cost breakdown analysis.\"\"\"\n",
        "\n",
        "    models = list(comprehensive_results.keys())\n",
        "\n",
        "    # Create cost breakdown chart\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(' Total Costs by Model', ' Cost per Query',\n",
        "                       ' Cost Efficiency (Cost/Quality)', ' Best Value Models'),\n",
        "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "               [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        "    )\n",
        "\n",
        "    # Prepare data\n",
        "    total_costs = [comprehensive_results[model]['total_cost_usd'] for model in models]\n",
        "    cost_per_query = [cost / 8 for cost in total_costs]  # Assuming 8 questions\n",
        "\n",
        "    # Calculate quality scores\n",
        "    quality_scores = []\n",
        "    for model in models:\n",
        "        quality = (comprehensive_results[model]['faithfulness'] +\n",
        "                  comprehensive_results[model]['answer_relevancy'] +\n",
        "                  comprehensive_results[model]['bleu_score'] * 10 +\n",
        "                  comprehensive_results[model]['cosine_similarity']) / 4\n",
        "        quality_scores.append(quality)\n",
        "\n",
        "    cost_efficiency = [cost / (quality + 0.001) for cost, quality in zip(total_costs, quality_scores)]\n",
        "\n",
        "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']\n",
        "\n",
        "    # 1. Total Costs\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=total_costs, name='Total Cost',\n",
        "               marker_color=colors, text=[f'${cost:.6f}' for cost in total_costs],\n",
        "               textposition='auto'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # 2. Cost per Query\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=cost_per_query, name='Cost per Query',\n",
        "               marker_color=colors, text=[f'${cost:.7f}' for cost in cost_per_query],\n",
        "               textposition='auto'),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # 3. Cost Efficiency\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=cost_efficiency, name='Cost/Quality Ratio',\n",
        "               marker_color=colors, text=[f'{eff:.6f}' for eff in cost_efficiency],\n",
        "               textposition='auto'),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # 4. Best Value (inverse of cost efficiency)\n",
        "    value_scores = [1/eff for eff in cost_efficiency]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=models, y=value_scores, name='Value Score',\n",
        "               marker_color=colors, text=[f'{val:.1f}' for val in value_scores],\n",
        "               textposition='auto'),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=800,\n",
        "        title_text=\" Detailed Cost Analysis Dashboard\",\n",
        "        title_x=0.5,\n",
        "        showlegend=False\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def display_comprehensive_summary_table(comprehensive_results):\n",
        "    \"\"\"Display a comprehensive summary table with all metrics.\"\"\"\n",
        "\n",
        "    # Create comprehensive DataFrame\n",
        "    summary_data = []\n",
        "    for model, metrics in comprehensive_results.items():\n",
        "        # Calculate composite scores\n",
        "        quality_score = (metrics['faithfulness'] + metrics['answer_relevancy'] +\n",
        "                        metrics['context_recall'] + metrics['context_precision']) / 4\n",
        "\n",
        "        value_score = quality_score / (metrics['total_cost_usd'] * 1000 + 0.001)\n",
        "\n",
        "        row = {\n",
        "            'Model': model,\n",
        "            'Provider': metrics['provider'],\n",
        "            'Total Cost ($)': f\"{metrics['total_cost_usd']:.6f}\",\n",
        "            'Avg Response Time (s)': f\"{metrics['avg_response_time']:.2f}\",\n",
        "            'Tokens/Second': f\"{metrics['tokens_per_second']:.1f}\",\n",
        "            'Success Rate (%)': f\"{metrics['success_rate']:.1f}\",\n",
        "            'Faithfulness': f\"{metrics['faithfulness']:.3f}\",\n",
        "            'Answer Relevancy': f\"{metrics['answer_relevancy']:.3f}\",\n",
        "            'Context Recall': f\"{metrics['context_recall']:.3f}\",\n",
        "            'Context Precision': f\"{metrics['context_precision']:.3f}\",\n",
        "            'BLEU Score': f\"{metrics['bleu_score']:.3f}\",\n",
        "            'Cosine Similarity': f\"{metrics['cosine_similarity']:.3f}\",\n",
        "            'Avg Words': f\"{metrics['avg_word_count']:.0f}\",\n",
        "            'Quality Score': f\"{quality_score:.3f}\",\n",
        "            'Value Score': f\"{value_score:.1f}\"\n",
        "        }\n",
        "        summary_data.append(row)\n",
        "\n",
        "    df = pd.DataFrame(summary_data)\n",
        "\n",
        "    print(\" COMPREHENSIVE MODEL COMPARISON TABLE\")\n",
        "    print(\"=\"*120)\n",
        "    display(df)\n",
        "\n",
        "    # Find best performers\n",
        "    print(\"\\n CHAMPIONS BY CATEGORY:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Best by quality metrics\n",
        "    best_faithfulness = comprehensive_results[max(comprehensive_results.keys(),\n",
        "                                                key=lambda x: comprehensive_results[x]['faithfulness'])]\n",
        "    print(f\" Best Faithfulness: {max(comprehensive_results.keys(), key=lambda x: comprehensive_results[x]['faithfulness'])}\")\n",
        "\n",
        "    best_relevancy = max(comprehensive_results.keys(), key=lambda x: comprehensive_results[x]['answer_relevancy'])\n",
        "    print(f\" Best Answer Relevancy: {best_relevancy}\")\n",
        "\n",
        "    best_speed = max(comprehensive_results.keys(), key=lambda x: comprehensive_results[x]['tokens_per_second'])\n",
        "    print(f\" Fastest: {best_speed}\")\n",
        "\n",
        "    best_cost = min(comprehensive_results.keys(), key=lambda x: comprehensive_results[x]['total_cost_usd'])\n",
        "    print(f\" Most Cost-Effective: {best_cost}\")\n",
        "\n",
        "    best_value = max(comprehensive_results.keys(),\n",
        "                    key=lambda x: (comprehensive_results[x]['faithfulness'] + comprehensive_results[x]['answer_relevancy']) /\n",
        "                                 (comprehensive_results[x]['total_cost_usd'] * 1000 + 0.001))\n",
        "    print(f\" Best Overall Value: {best_value}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "print(\" Enhanced visualization system ready!\")\n",
        "print(\" Features:\")\n",
        "print(\"    Ultimate performance dashboard (9 different charts)\")\n",
        "print(\"    Detailed cost breakdown analysis\")\n",
        "print(\"    Comprehensive summary tables\")\n",
        "print(\"    Best performer identification\")\n",
        "print(\"    Interactive visualizations\")\n",
        "print(\" Ready to create beautiful insights!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAOxcO9wyPJQ",
        "outputId": "8d46cdae-1660-480c-a17c-f6bbcf23bc6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Enhanced evaluation libraries loaded successfully!\n",
            " NLTK, Plotly, WordCloud, and scikit-learn ready for use\n"
          ]
        }
      ],
      "source": [
        "# Import additional libraries for enhanced evaluation and visualization\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.tokenize import word_tokenize\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "print(\" Enhanced evaluation libraries loaded successfully!\")\n",
        "print(\" NLTK, Plotly, WordCloud, and scikit-learn ready for use\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg2xzfQWzXqw",
        "outputId": "dff28f51-f35b-44aa-d5a5-3b8bfefb2de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring RAGAS to use Gemini...\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "\n",
        "# Configure RAGAS to use Gemini instead of OpenAI\n",
        "def setup_ragas_with_gemini():\n",
        "    \"\"\"Configure RAGAS to use Gemini for evaluation.\"\"\"\n",
        "    try:\n",
        "        from ragas.llms import LangchainLLMWrapper\n",
        "        from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "        from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "        from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "        # Set up Gemini LLM for RAGAS evaluation\n",
        "        gemini_llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            google_api_key=GOOGLE_API_KEY,\n",
        "            temperature=0.3,\n",
        "        )\n",
        "\n",
        "        # Set up Gemini embeddings for RAGAS\n",
        "        gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "            model=\"models/embedding-001\",\n",
        "            google_api_key=GOOGLE_API_KEY\n",
        "        )\n",
        "\n",
        "        # Wrap for RAGAS\n",
        "        ragas_llm = LangchainLLMWrapper(gemini_llm)\n",
        "        ragas_embeddings = LangchainEmbeddingsWrapper(gemini_embeddings)\n",
        "\n",
        "        return ragas_llm, ragas_embeddings\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up RAGAS with Gemini: {e}\")\n",
        "        print(\"Installing required packages...\")\n",
        "        return None, None\n",
        "\n",
        "# Set up RAGAS with Gemini\n",
        "print(\"Configuring RAGAS to use Gemini...\")\n",
        "ragas_llm, ragas_embeddings = setup_ragas_with_gemini()\n",
        "def evaluate_with_ragas(dataset: Dataset, model_name: str):\n",
        "    \"\"\"Evaluate a model using RAGAS metrics with Gemini.\"\"\"\n",
        "    try:\n",
        "        print(f\"Evaluating {model_name} with RAGAS...\")\n",
        "\n",
        "        # Import and configure metrics with Gemini\n",
        "        from ragas.metrics import (\n",
        "            answer_relevancy,\n",
        "            faithfulness,\n",
        "            context_recall,\n",
        "            context_precision,\n",
        "        )\n",
        "\n",
        "        if ragas_llm and ragas_embeddings:\n",
        "            # Configure metrics to use Gemini\n",
        "            answer_relevancy.llm = ragas_llm\n",
        "            answer_relevancy.embeddings = ragas_embeddings\n",
        "            faithfulness.llm = ragas_llm\n",
        "            context_recall.llm = ragas_llm\n",
        "            context_precision.llm = ragas_llm\n",
        "\n",
        "            # Define metrics to evaluate\n",
        "            metrics = [\n",
        "                answer_relevancy,\n",
        "                faithfulness,\n",
        "                context_recall,\n",
        "                context_precision,\n",
        "            ]\n",
        "        else:\n",
        "            print(\" Using simplified evaluation without external LLM dependencies\")\n",
        "            # Use basic metrics that don't require external APIs\n",
        "            from ragas.metrics import context_precision\n",
        "            metrics = [context_precision]\n",
        "\n",
        "        # Run evaluation\n",
        "        result = evaluate(\n",
        "            dataset=dataset,\n",
        "            metrics=metrics,\n",
        "        )\n",
        "\n",
        "        print(f\" {model_name} evaluation completed!\")\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error evaluating {model_name}: {e}\")\n",
        "        print(\"Trying alternative evaluation method...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex8ybOUpyJuR"
      },
      "outputs": [],
      "source": [
        "# Enhanced Evaluation with BLEU Score and Additional Metrics\n",
        "\n",
        "def calculate_bleu_score(reference_text: str, candidate_text: str) -> float:\n",
        "    \"\"\"Calculate BLEU score between reference and candidate text.\"\"\"\n",
        "    try:\n",
        "        # Tokenize the texts\n",
        "        reference_tokens = word_tokenize(reference_text.lower())\n",
        "        candidate_tokens = word_tokenize(candidate_text.lower())\n",
        "\n",
        "        # Calculate BLEU score with smoothing\n",
        "        smoothing = SmoothingFunction().method1\n",
        "        bleu_score = sentence_bleu([reference_tokens], candidate_tokens,\n",
        "                                 smoothing_function=smoothing)\n",
        "        return bleu_score\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating BLEU score: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_cosine_similarity(text1: str, text2: str) -> float:\n",
        "    \"\"\"Calculate cosine similarity between two texts.\"\"\"\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
        "        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "        return similarity\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating cosine similarity: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_response_length_score(text: str) -> dict:\n",
        "    \"\"\"Calculate various text length and complexity metrics.\"\"\"\n",
        "    words = text.split()\n",
        "    sentences = text.split('.')\n",
        "\n",
        "    return {\n",
        "        'word_count': len(words),\n",
        "        'sentence_count': len(sentences),\n",
        "        'avg_words_per_sentence': len(words) / max(len(sentences), 1),\n",
        "        'character_count': len(text)\n",
        "    }\n",
        "\n",
        "def enhanced_model_evaluation(model_results: dict, ground_truth: list) -> dict:\n",
        "    \"\"\"Perform comprehensive evaluation including BLEU scores (excludes Gemini).\"\"\"\n",
        "    print(\" Starting Enhanced Model Evaluation...\")\n",
        "    print(\" Note: Gemini is excluded from scoring (used only as baseline)\")\n",
        "    print(\"Calculating BLEU scores, cosine similarity, and text metrics...\")\n",
        "\n",
        "    enhanced_results = {}\n",
        "\n",
        "    # Only evaluate models that are not Gemini\n",
        "    models_to_evaluate = {k: v for k, v in model_results['model_answers'].items() if k != 'Gemini'}\n",
        "\n",
        "    for model_name in models_to_evaluate.keys():\n",
        "        print(f\" Evaluating {model_name}...\")\n",
        "\n",
        "        model_answers = model_results['model_answers'][model_name]\n",
        "        bleu_scores = []\n",
        "        cosine_scores = []\n",
        "        length_metrics = []\n",
        "\n",
        "        # Calculate metrics for each question\n",
        "        for i, (answer, reference) in enumerate(zip(model_answers, ground_truth)):\n",
        "            # BLEU Score\n",
        "            bleu = calculate_bleu_score(reference, answer)\n",
        "            bleu_scores.append(bleu)\n",
        "\n",
        "            # Cosine Similarity\n",
        "            cosine = calculate_cosine_similarity(reference, answer)\n",
        "            cosine_scores.append(cosine)\n",
        "\n",
        "            # Length and complexity metrics\n",
        "            length_metrics.append(calculate_response_length_score(answer))\n",
        "\n",
        "        # Aggregate results\n",
        "        enhanced_results[model_name] = {\n",
        "            'bleu_scores': bleu_scores,\n",
        "            'avg_bleu_score': np.mean(bleu_scores),\n",
        "            'cosine_similarities': cosine_scores,\n",
        "            'avg_cosine_similarity': np.mean(cosine_scores),\n",
        "            'length_metrics': length_metrics,\n",
        "            'avg_word_count': np.mean([m['word_count'] for m in length_metrics]),\n",
        "            'avg_sentence_count': np.mean([m['sentence_count'] for m in length_metrics]),\n",
        "            'avg_words_per_sentence': np.mean([m['avg_words_per_sentence'] for m in length_metrics])\n",
        "        }\n",
        "\n",
        "        print(f\"    {model_name}: BLEU={enhanced_results[model_name]['avg_bleu_score']:.3f}, \"\n",
        "              f\"Cosine={enhanced_results[model_name]['avg_cosine_similarity']:.3f}\")\n",
        "\n",
        "    print(f\" Enhanced evaluation completed for {len(enhanced_results)} models!\")\n",
        "    print(f\" Evaluated models: {list(enhanced_results.keys())}\")\n",
        "    print(f\" Baseline used: Gemini (not scored)\")\n",
        "    return enhanced_results\n",
        "\n",
        "# Run enhanced evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f7974757ddb4467aeebf2080e03f424",
            "cd85f213c05443778d37c38f1e192167",
            "0c1acb263c59433a8c732bf59736f8d6",
            "878d214690614956ad02649799a93f12",
            "05083ea7ec5143399ffcc4aadd9cec59",
            "f62f94dd9ef74594968e17b5456d1030",
            "e2127b51833247e6bece1b3bb26a2c7d",
            "62805881f00541728b88f7bf7380eac7",
            "ca9744cd4e0c43f7806df3762fc3e4ea",
            "2d6b038c670c464e8a99bc0514d09e26",
            "4b2242655ff848a6ac0fb5b79490c5b4",
            "26de4ce5aab2440a8c5b379b48817aa6",
            "f66f35790b824658b569da013922a75a",
            "ab2c47be04204fbf90414e1c70a4ae5a",
            "b32dcce24fea4785bf28e59ed5fadd67",
            "d246291589f8474081b775ee071ff43d",
            "9a16a65637cb4f27a0717d23aae1de91",
            "0189274652584d7cbbe325b5a0ee9a13",
            "26c870b032e94f27bcf055b02b9b3245",
            "83949dc8b6024b618de2b1bc1149efab",
            "d023352d8a7842b3a202f05e572df7aa",
            "518ebdb562e24b1387d383e179c9c832",
            "4d0058c1c9b4485798f0ab5e2e602ed5",
            "d9d23322d1d94e97a0c96e359e202948",
            "4da84654896447cba4e07f2e1eb83ea9",
            "dd25fa4cf59e436aa8944ab8bffb906e",
            "176927173ef7470fa05403f4a6549454",
            "e71f41ffd91d42f6ba01aecd539d0e07",
            "67b2132d1939464a9012d6c7c0740501",
            "1402d0f1d9c34e51967ca08d63af374b",
            "cdb819f2187a493fae732169679fbab7",
            "35da65a608ea46eeb21b14673461cdff",
            "9f8e9f0f0b1d4260a874bb455c964620",
            "5de1da4375574855b9055df7dfb21e93",
            "78cea82b488f4863b4d910fa7f258074",
            "16f1c2646aef4fafa271284d06a3f011",
            "b3fae5bf4c99431d8ad7d3ba32fa444b",
            "ec68f7d85d1249738cbfcf46402cbf8f",
            "b7f14f07a8414ab487c3e3ef09692b0d",
            "d420e05954734972bc27a74023c2b5a8",
            "f2809828843442cead54ccfdfb755a17",
            "a6463af890bd49cfa34b13173f0100f4",
            "17c59b63390240ca8abdd83216f1661e",
            "5b77e7b33fbd48e792b454fec2b5f697"
          ]
        },
        "id": "qLexmAZW2PaW",
        "outputId": "08682c0e-bfc8-4619-b5a5-65a793681d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " STARTING COMPREHENSIVE EVALUATION\n",
            "================================================================================\n",
            " Features included:\n",
            "    Auto-generated questions for RAGAS evaluation\n",
            "    Real-time cost tracking\n",
            "    Speed measurement\n",
            "    RAGAS metrics (faithfulness, relevancy, recall, precision)\n",
            "    BLEU scores and cosine similarity\n",
            "    Beautiful interactive visualizations\n",
            "    Comprehensive performance comparison\n",
            "\n",
            " Step 1: Generating Questions for RAGAS Evaluation\n",
            " Generating comprehensive questions for RAGAS evaluation...\n",
            " Successfully generated 8 questions for RAGAS evaluation!\n",
            " Generated Questions for RAGAS:\n",
            "   1. What did Galileo and Newton develop to understand motion?\n",
            "   2. Why does a box not move when pushed with a small force?\n",
            "   3. Summarize Galileo's experiment with the marble and inclined planes?\n",
            "   4. Compare the state of an object at rest versus in motion according to the text?\n",
            "   5. What can be inferred about the nature of force from the statement that no one has seen, tasted, or felt it?\n",
            "   6. What happens to the motion of a bicycle when pedaling stops?\n",
            "   7. What is required to accelerate the motion of an object?\n",
            "   8. Describe the relationship between pushing force and friction force when a box starts to move?\n",
            "\n",
            " Step 2: Getting Model Answers with Performance Tracking\n",
            " Getting answers from 5 models with performance tracking...\n",
            " Models: ['Gemini', 'Qwen', 'Llama', 'Gemma', 'DeepSeek']\n",
            " Tracking: Cost, Speed, Token Usage, Error Rate\n",
            "\n",
            " Processing question 1/8: What did Galileo and Newton develop to understand motion?...\n",
            "   Getting Gemini response...\n",
            "      Gemini: 96 chars, 3 contexts\n",
            "   Getting Qwen response...\n",
            "      Qwen: 705 chars, 3 contexts\n",
            "   Getting Llama response...\n",
            "      Llama: 1128 chars, 3 contexts\n",
            "   Getting Gemma response...\n",
            "      Gemma: 121 chars, 3 contexts\n",
            "   Getting DeepSeek response...\n",
            "      DeepSeek: 350 chars, 3 contexts\n",
            "\n",
            " Processing question 2/8: Why does a box not move when pushed with a small force?...\n",
            "   Getting Gemini response...\n",
            "      Gemini: 234 chars, 3 contexts\n",
            "   Getting Qwen response...\n",
            "      Qwen: 1073 chars, 3 contexts\n",
            "   Getting Llama response...\n",
            "      Llama: 2267 chars, 3 contexts\n",
            "   Getting Gemma response...\n",
            "      Gemma: 140 chars, 3 contexts\n",
            "   Getting DeepSeek response...\n",
            "      DeepSeek: 271 chars, 3 contexts\n",
            "\n",
            " Processing question 3/8: Summarize Galileo's experiment with the marble and inclined ...\n",
            "   Getting Gemini response...\n",
            "      Gemini: 637 chars, 3 contexts\n",
            "   Getting Qwen response...\n",
            "      Qwen: 1093 chars, 3 contexts\n",
            "   Getting Llama response...\n",
            "      Llama: 2481 chars, 3 contexts\n",
            "   Getting Gemma response...\n",
            "      Gemma: 627 chars, 3 contexts\n",
            "   Getting DeepSeek response...\n",
            "      DeepSeek: 1023 chars, 3 contexts\n",
            "\n",
            " Processing question 4/8: Compare the state of an object at rest versus in motion acco...\n",
            "   Getting Gemini response...\n",
            "      Gemini: 253 chars, 3 contexts\n",
            "   Getting Qwen response...\n",
            "      Qwen: 811 chars, 3 contexts\n",
            "   Getting Llama response...\n",
            "      Llama: 2453 chars, 3 contexts\n",
            "   Getting Gemma response...\n",
            "      Gemma: 150 chars, 3 contexts\n",
            "   Getting DeepSeek response...\n",
            "      DeepSeek: 636 chars, 3 contexts\n",
            "\n",
            " Processing question 5/8: What can be inferred about the nature of force from the stat...\n",
            "   Getting Gemini response...\n",
            "      Gemini: 88 chars, 3 contexts\n",
            "   Getting Qwen response...\n",
            "      Qwen: 614 chars, 3 contexts\n",
            "   Getting Llama response...\n",
            "      Llama: 2326 chars, 3 contexts\n",
            "   Getting Gemma response...\n",
            "      Gemma: 213 chars, 3 contexts\n",
            "   Getting DeepSeek response...\n",
            "      DeepSeek: 622 chars, 3 contexts\n",
            "\n",
            " Processing question 6/8: What happens to the motion of a bicycle when pedaling stops?...\n",
            "   Getting Gemini response...\n",
            "      Gemini: 129 chars, 3 contexts\n",
            "   Getting Qwen response...\n",
            "      Qwen: 603 chars, 3 contexts\n",
            "   Getting Llama response...\n",
            "      Llama: 2734 chars, 3 contexts\n",
            "   Getting Gemma response...\n",
            "      Gemma: 153 chars, 3 contexts\n",
            "   Getting DeepSeek response...\n",
            "      DeepSeek: 137 chars, 3 contexts\n",
            "\n",
            " Processing question 7/8: What is required to accelerate the motion of an object?...\n",
            "   Getting Gemini response...\n",
            "      Gemini: 71 chars, 3 contexts\n",
            "   Getting Qwen response...\n",
            "      Qwen: 863 chars, 3 contexts\n",
            "   Getting Llama response...\n",
            "      Llama: 2605 chars, 3 contexts\n",
            "   Getting Gemma response...\n",
            "      Gemma: 73 chars, 3 contexts\n",
            "   Getting DeepSeek response...\n",
            "      DeepSeek: 365 chars, 3 contexts\n",
            "\n",
            " Processing question 8/8: Describe the relationship between pushing force and friction...\n",
            "   Getting Gemini response...\n",
            "      Gemini: 116 chars, 3 contexts\n",
            "   Getting Qwen response...\n",
            "      Qwen: 2564 chars, 3 contexts\n",
            "   Getting Llama response...\n",
            "      Llama: 2799 chars, 3 contexts\n",
            "   Getting Gemma response...\n",
            "      Gemma: 89 chars, 3 contexts\n",
            "   Getting DeepSeek response...\n",
            "      DeepSeek: 464 chars, 3 contexts\n",
            "\n",
            " Completed getting answers from all 5 models!\n",
            "\n",
            " COST & PERFORMANCE SUMMARY:\n",
            "============================================================\n",
            "Gemini:\n",
            "   Total Cost: $0.008143\n",
            "    Avg Response Time: 1.22s\n",
            "   Tokens/Second: 554.3\n",
            "   Success Rate: 100.0%\n",
            "\n",
            "Qwen:\n",
            "   Total Cost: $0.001383\n",
            "    Avg Response Time: 5.06s\n",
            "   Tokens/Second: 170.9\n",
            "   Success Rate: 100.0%\n",
            "\n",
            "Llama:\n",
            "   Total Cost: $0.005612\n",
            "    Avg Response Time: 12.58s\n",
            "   Tokens/Second: 94.6\n",
            "   Success Rate: 100.0%\n",
            "\n",
            "Gemma:\n",
            "   Total Cost: $0.001084\n",
            "    Avg Response Time: 0.74s\n",
            "   Tokens/Second: 909.8\n",
            "   Success Rate: 100.0%\n",
            "\n",
            "DeepSeek:\n",
            "   Total Cost: $0.000954\n",
            "    Avg Response Time: 2.52s\n",
            "   Tokens/Second: 294.3\n",
            "   Success Rate: 100.0%\n",
            "\n",
            " Step 3: Setting Up Ground Truth and RAGAS Evaluation\n",
            " Models to evaluate with RAGAS: ['Qwen', 'Llama', 'Gemma', 'DeepSeek']\n",
            " Ground truth provider: Gemini (excluded from scoring)\n",
            "\n",
            " Step 4: Running RAGAS Evaluation\n",
            " Preparing RAGAS dataset for Qwen...\n",
            " Preparing RAGAS dataset for Llama...\n",
            " Preparing RAGAS dataset for Gemma...\n",
            " Preparing RAGAS dataset for DeepSeek...\n",
            " Running RAGAS evaluation for Qwen...\n",
            "Evaluating Qwen with RAGAS...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f7974757ddb4467aeebf2080e03f424",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Qwen evaluation completed!\n",
            " Running RAGAS evaluation for Llama...\n",
            "Evaluating Llama with RAGAS...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26de4ce5aab2440a8c5b379b48817aa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Llama evaluation completed!\n",
            " Running RAGAS evaluation for Gemma...\n",
            "Evaluating Gemma with RAGAS...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d0058c1c9b4485798f0ab5e2e602ed5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Gemma evaluation completed!\n",
            " Running RAGAS evaluation for DeepSeek...\n",
            "Evaluating DeepSeek with RAGAS...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5de1da4375574855b9055df7dfb21e93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " DeepSeek evaluation completed!\n",
            " Step 5: Running Enhanced Evaluation (BLEU, Cosine Similarity)\n",
            " Starting Enhanced Model Evaluation...\n",
            " Note: Gemini is excluded from scoring (used only as baseline)\n",
            "Calculating BLEU scores, cosine similarity, and text metrics...\n",
            " Evaluating Qwen...\n",
            "    Qwen: BLEU=0.088, Cosine=0.542\n",
            " Evaluating Llama...\n",
            "    Llama: BLEU=0.033, Cosine=0.417\n",
            " Evaluating Gemma...\n",
            "    Gemma: BLEU=0.369, Cosine=0.603\n",
            " Evaluating DeepSeek...\n",
            "    DeepSeek: BLEU=0.224, Cosine=0.631\n",
            " Enhanced evaluation completed for 4 models!\n",
            " Evaluated models: ['Qwen', 'Llama', 'Gemma', 'DeepSeek']\n",
            " Baseline used: Gemini (not scored)\n",
            " Step 6: Creating Comprehensive Results\n",
            "\n",
            "================================================================================\n",
            " COMPREHENSIVE EVALUATION COMPLETED!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#  RUN THE COMPLETE ENHANCED EVALUATION\n",
        "\n",
        "# Execute the comprehensive evaluation\n",
        "evaluation_results = run_comprehensive_evaluation_with_ragas()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" COMPREHENSIVE EVALUATION COMPLETED!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IGKKpj-mv4AR",
        "outputId": "cdc76454-a07c-4d96-feec-eec07025664f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " COMPREHENSIVE MODEL COMPARISON TABLE\n",
            "========================================================================================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\ud83c\\udf89 EVALUATION COMPLETE! All requested features implemented successfully!\\\")\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Gemma\",\n          \"Llama\",\n          \"Qwen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Provider\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Google\",\n          \"Meta\",\n          \"Qwen/Alibaba\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Cost ($)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.001084\",\n          \"0.005612\",\n          \"0.001383\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg Response Time (s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.74\",\n          \"12.58\",\n          \"5.06\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tokens/Second\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"909.8\",\n          \"94.6\",\n          \"170.9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Success Rate (%)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"100.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Faithfulness\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"1.000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer Relevancy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.924\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Context Recall\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1.000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Context Precision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.927\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BLEU Score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.369\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cosine Similarity\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.603\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg Words\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"33\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quality Score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.963\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value Score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0.9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-87d19b00-7644-4675-811c-8732c60f225a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Provider</th>\n",
              "      <th>Total Cost ($)</th>\n",
              "      <th>Avg Response Time (s)</th>\n",
              "      <th>Tokens/Second</th>\n",
              "      <th>Success Rate (%)</th>\n",
              "      <th>Faithfulness</th>\n",
              "      <th>Answer Relevancy</th>\n",
              "      <th>Context Recall</th>\n",
              "      <th>Context Precision</th>\n",
              "      <th>BLEU Score</th>\n",
              "      <th>Cosine Similarity</th>\n",
              "      <th>Avg Words</th>\n",
              "      <th>Quality Score</th>\n",
              "      <th>Value Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Qwen</td>\n",
              "      <td>Qwen/Alibaba</td>\n",
              "      <td>0.001383</td>\n",
              "      <td>5.06</td>\n",
              "      <td>170.9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.937</td>\n",
              "      <td>0.899</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.927</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.542</td>\n",
              "      <td>173</td>\n",
              "      <td>0.941</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gemma</td>\n",
              "      <td>Google</td>\n",
              "      <td>0.001084</td>\n",
              "      <td>0.74</td>\n",
              "      <td>909.8</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.924</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.927</td>\n",
              "      <td>0.369</td>\n",
              "      <td>0.603</td>\n",
              "      <td>33</td>\n",
              "      <td>0.963</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DeepSeek</td>\n",
              "      <td>DeepSeek</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>2.52</td>\n",
              "      <td>294.3</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.938</td>\n",
              "      <td>0.912</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.927</td>\n",
              "      <td>0.224</td>\n",
              "      <td>0.631</td>\n",
              "      <td>82</td>\n",
              "      <td>0.944</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Llama</td>\n",
              "      <td>Meta</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>12.58</td>\n",
              "      <td>94.6</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.954</td>\n",
              "      <td>0.941</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.927</td>\n",
              "      <td>0.033</td>\n",
              "      <td>0.417</td>\n",
              "      <td>417</td>\n",
              "      <td>0.956</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87d19b00-7644-4675-811c-8732c60f225a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87d19b00-7644-4675-811c-8732c60f225a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87d19b00-7644-4675-811c-8732c60f225a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-78bc86f8-b4b4-4f96-aa1a-927f3e85a0ed\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78bc86f8-b4b4-4f96-aa1a-927f3e85a0ed')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-78bc86f8-b4b4-4f96-aa1a-927f3e85a0ed button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Model      Provider Total Cost ($) Avg Response Time (s) Tokens/Second  \\\n",
              "0      Qwen  Qwen/Alibaba       0.001383                  5.06         170.9   \n",
              "1     Gemma        Google       0.001084                  0.74         909.8   \n",
              "2  DeepSeek      DeepSeek       0.000954                  2.52         294.3   \n",
              "3     Llama          Meta       0.005612                 12.58          94.6   \n",
              "\n",
              "  Success Rate (%) Faithfulness Answer Relevancy Context Recall  \\\n",
              "0            100.0        0.937            0.899          1.000   \n",
              "1            100.0        1.000            0.924          1.000   \n",
              "2            100.0        0.938            0.912          1.000   \n",
              "3            100.0        0.954            0.941          1.000   \n",
              "\n",
              "  Context Precision BLEU Score Cosine Similarity Avg Words Quality Score  \\\n",
              "0             0.927      0.088             0.542       173         0.941   \n",
              "1             0.927      0.369             0.603        33         0.963   \n",
              "2             0.927      0.224             0.631        82         0.944   \n",
              "3             0.927      0.033             0.417       417         0.956   \n",
              "\n",
              "  Value Score  \n",
              "0         0.7  \n",
              "1         0.9  \n",
              "2         1.0  \n",
              "3         0.2  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " CHAMPIONS BY CATEGORY:\n",
            "==================================================\n",
            " Best Faithfulness: Gemma\n",
            " Best Answer Relevancy: Llama\n",
            " Fastest: Gemma\n",
            " Most Cost-Effective: DeepSeek\n",
            " Best Overall Value: DeepSeek\n",
            "\n",
            "================================================================================\n",
            " GENERATING INTERACTIVE VISUALIZATIONS...\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            " FINAL SUMMARY AND RECOMMENDATIONS\n",
            "================================================================================\n",
            " TOP PERFORMERS BY CATEGORY:\n",
            "--------------------------------------------------\n",
            " Best Quality: Gemma (Score: 0.963)\n",
            " Best Value: DeepSeek (Quality/Cost: 1.0)\n",
            " Fastest: Gemma (909.8 tokens/sec)\n",
            " Cheapest: DeepSeek ($0.000954)\n",
            "\n",
            " RECOMMENDATIONS:\n",
            "------------------------------\n",
            " For highest quality answers: Use Gemma\n",
            " For best value/performance ratio: Use DeepSeek\n",
            " For fastest responses: Use Gemma\n",
            " For minimum cost: Use DeepSeek\n",
            "\n",
            " EVALUATION METHODOLOGY:\n",
            "----------------------------------------\n",
            " Auto-generated questions designed for RAGAS evaluation\n",
            " RAGAS metrics: faithfulness, answer relevancy, context recall/precision\n",
            " BLEU scores and cosine similarity for semantic analysis\n",
            " Real-time cost tracking with OpenRouter pricing\n",
            " Speed measurement (response time, tokens/second)\n",
            " Comprehensive quality vs cost vs speed analysis\n",
            "\n",
            " TOTAL EVALUATION COST: $0.009033\n",
            " Questions evaluated: 8\n",
            " Models compared: 4\n",
            " Metrics calculated: 15+ different performance indicators\n",
            "\n",
            " ENHANCED FEATURES DELIVERED:\n",
            "==================================================\n",
            " Auto-generated questions specifically for RAGAS\n",
            " Real-time cost analysis with OpenRouter API pricing\n",
            " Speed measurement and tokens/second calculation\n",
            " Beautiful interactive visualizations (9 different charts)\n",
            " Comprehensive performance comparison dashboard\n",
            " Cost vs Quality vs Speed trade-off analysis\n",
            " Best value recommendations\n",
            " Detailed summary tables with all metrics\n",
            "\n",
            " EVALUATION COMPLETE! All requested features implemented successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Display comprehensive summary table\n",
        "summary_df = display_comprehensive_summary_table(evaluation_results['comprehensive_results'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" GENERATING INTERACTIVE VISUALIZATIONS...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create and display ultimate performance dashboard\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" FINAL SUMMARY AND RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Generate final recommendations\n",
        "comprehensive_results = evaluation_results['comprehensive_results']\n",
        "\n",
        "print(\" TOP PERFORMERS BY CATEGORY:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Find best performers\n",
        "models = list(comprehensive_results.keys())\n",
        "\n",
        "# Best overall quality\n",
        "quality_scores = {model: (comprehensive_results[model]['faithfulness'] +\n",
        "                         comprehensive_results[model]['answer_relevancy'] +\n",
        "                         comprehensive_results[model]['context_recall'] +\n",
        "                         comprehensive_results[model]['context_precision']) / 4\n",
        "                 for model in models}\n",
        "best_quality = max(quality_scores.keys(), key=lambda x: quality_scores[x])\n",
        "\n",
        "# Best cost efficiency\n",
        "cost_efficiency = {model: quality_scores[model] / (comprehensive_results[model]['total_cost_usd'] * 1000 + 0.001)\n",
        "                  for model in models}\n",
        "best_value = max(cost_efficiency.keys(), key=lambda x: cost_efficiency[x])\n",
        "\n",
        "# Fastest\n",
        "best_speed = max(models, key=lambda x: comprehensive_results[x]['tokens_per_second'])\n",
        "\n",
        "# Most cost-effective\n",
        "best_cost = min(models, key=lambda x: comprehensive_results[x]['total_cost_usd'])\n",
        "\n",
        "print(f\" Best Quality: {best_quality} (Score: {quality_scores[best_quality]:.3f})\")\n",
        "print(f\" Best Value: {best_value} (Quality/Cost: {cost_efficiency[best_value]:.1f})\")\n",
        "print(f\" Fastest: {best_speed} ({comprehensive_results[best_speed]['tokens_per_second']:.1f} tokens/sec)\")\n",
        "print(f\" Cheapest: {best_cost} (${comprehensive_results[best_cost]['total_cost_usd']:.6f})\")\n",
        "\n",
        "print(\"\\n RECOMMENDATIONS:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\" For highest quality answers: Use {best_quality}\")\n",
        "print(f\" For best value/performance ratio: Use {best_value}\")\n",
        "print(f\" For fastest responses: Use {best_speed}\")\n",
        "print(f\" For minimum cost: Use {best_cost}\")\n",
        "\n",
        "print(\"\\n EVALUATION METHODOLOGY:\")\n",
        "print(\"-\" * 40)\n",
        "print(\" Auto-generated questions designed for RAGAS evaluation\")\n",
        "print(\" RAGAS metrics: faithfulness, answer relevancy, context recall/precision\")\n",
        "print(\" BLEU scores and cosine similarity for semantic analysis\")\n",
        "print(\" Real-time cost tracking with OpenRouter pricing\")\n",
        "print(\" Speed measurement (response time, tokens/second)\")\n",
        "print(\" Comprehensive quality vs cost vs speed analysis\")\n",
        "\n",
        "print(f\"\\n TOTAL EVALUATION COST: ${sum(comprehensive_results[model]['total_cost_usd'] for model in models):.6f}\")\n",
        "print(f\" Questions evaluated: {len(evaluation_results['questions'])}\")\n",
        "print(f\" Models compared: {len(models)}\")\n",
        "print(f\" Metrics calculated: 15+ different performance indicators\")\n",
        "\n",
        "print(\"\\n ENHANCED FEATURES DELIVERED:\")\n",
        "print(\"=\"*50)\n",
        "print(\" Auto-generated questions specifically for RAGAS\")\n",
        "print(\" Real-time cost analysis with OpenRouter API pricing\")\n",
        "print(\" Speed measurement and tokens/second calculation\")\n",
        "print(\" Beautiful interactive visualizations (9 different charts)\")\n",
        "print(\" Comprehensive performance comparison dashboard\")\n",
        "print(\" Cost vs Quality vs Speed trade-off analysis\")\n",
        "print(\" Best value recommendations\")\n",
        "print(\" Detailed summary tables with all metrics\")\n",
        "\n",
        "print(\"\\n EVALUATION COMPLETE! All requested features implemented successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wjgRxpQK19kO",
        "outputId": "07b6a515-1ca8-4783-d2d2-1f8ec2c84de1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"44334316-e1e0-49a8-b007-e71939cafbed\" class=\"plotly-graph-div\" style=\"height:1200px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"44334316-e1e0-49a8-b007-e71939cafbed\")) {                    Plotly.newPlot(                        \"44334316-e1e0-49a8-b007-e71939cafbed\",                        [{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\"]},\"name\":\"Cost (USD)\",\"text\":[\"$0.001383\",\"$0.001084\",\"$0.000954\",\"$0.005612\"],\"textposition\":\"auto\",\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[0.0013830000000000001,0.0010838,0.0009539600000000002,0.00561208],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\"]},\"name\":\"Response Time (s)\",\"text\":[\"5.06s\",\"0.74s\",\"2.52s\",\"12.58s\"],\"textposition\":\"auto\",\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[5.058811843395233,0.7445564866065979,2.52402925491333,12.575125128030777],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"fill\":\"toself\",\"line\":{\"color\":\"#FF6B6B\"},\"name\":\"Qwen\",\"r\":[0.9368131868131868,0.8986744052196551,1.0,0.9270833332848958],\"theta\":[\"faithfulness\",\"answer_relevancy\",\"context_recall\",\"context_precision\"],\"type\":\"scatterpolar\",\"subplot\":\"polar\"},{\"fill\":\"toself\",\"line\":{\"color\":\"#4ECDC4\"},\"name\":\"Gemma\",\"r\":[1.0,0.9238594802701898,1.0,0.9270833332848958],\"theta\":[\"faithfulness\",\"answer_relevancy\",\"context_recall\",\"context_precision\"],\"type\":\"scatterpolar\",\"subplot\":\"polar\"},{\"fill\":\"toself\",\"line\":{\"color\":\"#45B7D1\"},\"name\":\"DeepSeek\",\"r\":[0.9375,0.9116132842099065,1.0,0.9270833332848958],\"theta\":[\"faithfulness\",\"answer_relevancy\",\"context_recall\",\"context_precision\"],\"type\":\"scatterpolar\",\"subplot\":\"polar\"},{\"marker\":{\"color\":\"lightblue\"},\"name\":\"BLEU Score\",\"opacity\":0.7,\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[0.08752047089089765,0.3690264129713719,0.22438529404695462,0.032763425055681396],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":\"lightcoral\"},\"name\":\"Cosine Similarity\",\"opacity\":0.7,\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[0.5423978871750034,0.603107987641917,0.630659360378877,0.4165444856216284],\"yaxis\":\"y3\",\"type\":\"bar\",\"xaxis\":\"x3\"},{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\"],\"size\":12},\"mode\":\"markers+text\",\"name\":\"Length vs Quality\",\"text\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"textposition\":\"top center\",\"x\":[173.375,33.0,82.125,416.75],\"y\":[0.917743796016421,0.9619297401350949,0.9245566421049533,0.9475264297362077],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\"]},\"name\":\"Overall Score\",\"text\":[\"0.670\",\"1.352\",\"0.992\",\"0.447\"],\"textposition\":\"auto\",\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[0.6703071630613431,1.3522442085638837,0.9922399888863009,0.4472376987054603],\"type\":\"bar\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\"],\"size\":15},\"mode\":\"markers+text\",\"name\":\"Cost vs Quality\",\"text\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"textposition\":\"top center\",\"x\":[0.0013830000000000001,0.0010838,0.0009539600000000002,0.00561208],\"y\":[0.917743796016421,0.9619297401350949,0.9245566421049533,0.9475264297362077],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\"],\"size\":15},\"mode\":\"markers+text\",\"name\":\"Speed vs Quality\",\"text\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"textposition\":\"top center\",\"x\":[5.058811843395233,0.7445564866065979,2.52402925491333,12.575125128030777],\"y\":[0.917743796016421,0.9619297401350949,0.9245566421049533,0.9475264297362077],\"type\":\"scatter\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\"]},\"name\":\"Value Score (Quality\\u002fCost)\",\"text\":[\"0.7\",\"0.9\",\"1.0\",\"0.2\"],\"textposition\":\"auto\",\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[0.6631096792026163,0.8867346424549178,0.9681626896466375,0.16880686356442587],\"type\":\"bar\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2888888888888889],\"title\":{\"text\":\"Models\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.7777777777777778,1.0],\"title\":{\"text\":\"Cost (USD)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.35555555555555557,0.6444444444444445],\"title\":{\"text\":\"Models\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.7777777777777778,1.0],\"title\":{\"text\":\"Response Time (s)\"}},\"polar\":{\"domain\":{\"x\":[0.7111111111111111,1.0],\"y\":[0.7777777777777778,1.0]}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.2888888888888889]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.3888888888888889,0.6111111111111112]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.35555555555555557,0.6444444444444445],\"title\":{\"text\":\"Word Count\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.3888888888888889,0.6111111111111112],\"title\":{\"text\":\"Quality Score\"}},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.7111111111111111,1.0]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.3888888888888889,0.6111111111111112]},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.0,0.2888888888888889],\"title\":{\"text\":\"Cost (USD)\"}},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,0.22222222222222224],\"title\":{\"text\":\"Quality Score\"}},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.35555555555555557,0.6444444444444445],\"title\":{\"text\":\"Response Time (s)\"}},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,0.22222222222222224],\"title\":{\"text\":\"Quality Score\"}},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.7111111111111111,1.0]},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,0.22222222222222224]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Cost Analysis\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Speed Performance\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" RAGAS Quality Metrics\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" BLEU & Cosine Similarity\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6111111111111112,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Response Characteristics\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6111111111111112,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Overall Rankings\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6111111111111112,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Cost vs Quality Trade-off\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.22222222222222224,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Speed vs Quality Trade-off\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.22222222222222224,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Best Value Analysis\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.22222222222222224,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"font\":{\"size\":24},\"text\":\" Ultimate Model Performance Dashboard - Cost, Speed & Quality Analysis\",\"x\":0.5},\"height\":1200,\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('44334316-e1e0-49a8-b007-e71939cafbed');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"23d5e585-1bfc-4c50-a812-66922078ba6c\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"23d5e585-1bfc-4c50-a812-66922078ba6c\")) {                    Plotly.newPlot(                        \"23d5e585-1bfc-4c50-a812-66922078ba6c\",                        [{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\",\"#FECA57\"]},\"name\":\"Total Cost\",\"text\":[\"$0.001383\",\"$0.001084\",\"$0.000954\",\"$0.005612\"],\"textposition\":\"auto\",\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[0.0013830000000000001,0.0010838,0.0009539600000000002,0.00561208],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\",\"#FECA57\"]},\"name\":\"Cost per Query\",\"text\":[\"$0.0001729\",\"$0.0001355\",\"$0.0001192\",\"$0.0007015\"],\"textposition\":\"auto\",\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[0.00017287500000000001,0.000135475,0.00011924500000000003,0.00070151],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\",\"#FECA57\"]},\"name\":\"Cost\\u002fQuality Ratio\",\"text\":[\"0.001698\",\"0.000697\",\"0.000807\",\"0.008493\"],\"textposition\":\"auto\",\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[0.00169844851707913,0.000696839513522438,0.000807136675979581,0.0084927556241898],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[\"#FF6B6B\",\"#4ECDC4\",\"#45B7D1\",\"#96CEB4\",\"#FECA57\"]},\"name\":\"Value Score\",\"text\":[\"588.8\",\"1435.1\",\"1238.9\",\"117.7\"],\"textposition\":\"auto\",\"x\":[\"Qwen\",\"Gemma\",\"DeepSeek\",\"Llama\"],\"y\":[588.7726298114284,1435.0506545547669,1238.947541054742,117.74741253024091],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Total Costs by Model\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Cost per Query\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Cost Efficiency (Cost\\u002fQuality)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\" Best Value Models\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\" Detailed Cost Analysis Dashboard\",\"x\":0.5},\"height\":800,\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('23d5e585-1bfc-4c50-a812-66922078ba6c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create and display ultimate performance dashboard\n",
        "ultimate_dashboard = create_ultimate_performance_dashboard(evaluation_results['comprehensive_results'])\n",
        "ultimate_dashboard.show()\n",
        "\n",
        "# Create and display cost breakdown analysis\n",
        "cost_dashboard = create_cost_breakdown_analysis(evaluation_results['comprehensive_results'])\n",
        "cost_dashboard.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R1Huz6Mozzq",
        "outputId": "73c8dafb-c336-4b95-ae21-56c8eafc3ab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ENHANCED PDF Q&A COMPARISON SYSTEM - USAGE GUIDE\n",
            "================================================================================\n",
            "\n",
            " NEW FEATURES ADDED:\n",
            "\n",
            "1.  BLEU Score Evaluation\n",
            "   - Measures translation quality between model answers and reference\n",
            "   - Higher scores indicate better semantic similarity to ground truth\n",
            "   - Integrated with existing RAGAS metrics\n",
            "\n",
            "2.  Beautiful Interactive Visualizations\n",
            "   - Comprehensive dashboard with multiple chart types\n",
            "   - Interactive Plotly charts with hover effects\n",
            "   - Radar charts for multi-metric comparison\n",
            "   - Box plots for response length distribution\n",
            "   - Color-coded model comparison\n",
            "\n",
            "3.  Automatic Query Generation\n",
            "   - Uses Gemini to generate evaluation questions from your PDFs\n",
            "   - Creates diverse question types (factual, analytical, inference, etc.)\n",
            "   - Automatically runs comprehensive evaluation with generated questions\n",
            "   - No manual question creation needed\n",
            "\n",
            " HOW TO USE:\n",
            "\n",
            "1. To generate custom questions and run evaluation:\n",
            "   ```python\n",
            "   new_questions, results, enhanced_metrics = create_custom_evaluation_with_generated_questions(8)\n",
            "   ```\n",
            "\n",
            "2. To evaluate with BLEU scores on your own questions:\n",
            "   ```python\n",
            "   your_questions = [\"Your question 1?\", \"Your question 2?\"]\n",
            "   results = get_model_answers(your_questions)\n",
            "   enhanced_results = enhanced_model_evaluation(results, ground_truth_answers)\n",
            "   ```\n",
            "\n",
            "3. To create beautiful visualizations:\n",
            "   ```python\n",
            "   dashboard = create_model_comparison_dashboard(enhanced_results, evaluation_results)\n",
            "   dashboard.show()\n",
            "   ```\n",
            "\n",
            "4. To ask interactive questions:\n",
            "   ```python\n",
            "   ask_interactive_question(\"What are the main conclusions of this research?\")\n",
            "   ```\n",
            "\n",
            " All evaluations now include:\n",
            "    RAGAS metrics (context recall, precision, faithfulness, answer relevancy)\n",
            "    BLEU scores for semantic similarity\n",
            "    Cosine similarity using TF-IDF\n",
            "    Response length and complexity analysis\n",
            "    Beautiful interactive visualizations\n",
            "    Comprehensive model rankings\n",
            "\n",
            " Your system is now ready for advanced multi-model evaluation!\n",
            "\n",
            "\n",
            " QUICK EXAMPLE - Generate 3 questions and evaluate:\n"
          ]
        }
      ],
      "source": [
        "#  HOW TO USE THE ENHANCED FEATURES\n",
        "\n",
        "print(\" ENHANCED PDF Q&A COMPARISON SYSTEM - USAGE GUIDE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\"\"\n",
        " NEW FEATURES ADDED:\n",
        "\n",
        "1.  BLEU Score Evaluation\n",
        "   - Measures translation quality between model answers and reference\n",
        "   - Higher scores indicate better semantic similarity to ground truth\n",
        "   - Integrated with existing RAGAS metrics\n",
        "\n",
        "2.  Beautiful Interactive Visualizations\n",
        "   - Comprehensive dashboard with multiple chart types\n",
        "   - Interactive Plotly charts with hover effects\n",
        "   - Radar charts for multi-metric comparison\n",
        "   - Box plots for response length distribution\n",
        "   - Color-coded model comparison\n",
        "\n",
        "3.  Automatic Query Generation\n",
        "   - Uses Gemini to generate evaluation questions from your PDFs\n",
        "   - Creates diverse question types (factual, analytical, inference, etc.)\n",
        "   - Automatically runs comprehensive evaluation with generated questions\n",
        "   - No manual question creation needed\n",
        "\n",
        " HOW TO USE:\n",
        "\n",
        "1. To generate custom questions and run evaluation:\n",
        "   ```python\n",
        "   new_questions, results, enhanced_metrics = create_custom_evaluation_with_generated_questions(8)\n",
        "   ```\n",
        "\n",
        "2. To evaluate with BLEU scores on your own questions:\n",
        "   ```python\n",
        "   your_questions = [\"Your question 1?\", \"Your question 2?\"]\n",
        "   results = get_model_answers(your_questions)\n",
        "   enhanced_results = enhanced_model_evaluation(results, ground_truth_answers)\n",
        "   ```\n",
        "\n",
        "3. To create beautiful visualizations:\n",
        "   ```python\n",
        "   dashboard = create_model_comparison_dashboard(enhanced_results, evaluation_results)\n",
        "   dashboard.show()\n",
        "   ```\n",
        "\n",
        "4. To ask interactive questions:\n",
        "   ```python\n",
        "   ask_interactive_question(\"What are the main conclusions of this research?\")\n",
        "   ```\n",
        "\n",
        " All evaluations now include:\n",
        "    RAGAS metrics (context recall, precision, faithfulness, answer relevancy)\n",
        "    BLEU scores for semantic similarity\n",
        "    Cosine similarity using TF-IDF\n",
        "    Response length and complexity analysis\n",
        "    Beautiful interactive visualizations\n",
        "    Comprehensive model rankings\n",
        "\n",
        " Your system is now ready for advanced multi-model evaluation!\n",
        "\"\"\")\n",
        "\n",
        "# Example: Quick custom evaluation\n",
        "print(\"\\n QUICK EXAMPLE - Generate 3 questions and evaluate:\")\n",
        "\n",
        "def quick_custom_evaluation():\n",
        "    \"\"\"Quick demonstration of enhanced features.\"\"\"\n",
        "    custom_questions = generate_questions_from_document(3)\n",
        "    print(\"Generated questions:\")\n",
        "    for i, q in enumerate(custom_questions, 1):\n",
        "        print(f\"  {i}. {q}\")\n",
        "\n",
        "    # Show first generated question interactively\n",
        "    if custom_questions:\n",
        "        print(f\"\\n Interactive demo with question: '{custom_questions[0]}'\")\n",
        "        ask_interactive_question(custom_questions[0])\n",
        "\n",
        "# Uncomment the line below to run quick demonstration\n",
        "# quick_custom_evaluation()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0189274652584d7cbbe325b5a0ee9a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05083ea7ec5143399ffcc4aadd9cec59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1acb263c59433a8c732bf59736f8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62805881f00541728b88f7bf7380eac7",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca9744cd4e0c43f7806df3762fc3e4ea",
            "value": 32
          }
        },
        "1402d0f1d9c34e51967ca08d63af374b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f1c2646aef4fafa271284d06a3f011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2809828843442cead54ccfdfb755a17",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6463af890bd49cfa34b13173f0100f4",
            "value": 32
          }
        },
        "176927173ef7470fa05403f4a6549454": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c59b63390240ca8abdd83216f1661e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c870b032e94f27bcf055b02b9b3245": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26de4ce5aab2440a8c5b379b48817aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f66f35790b824658b569da013922a75a",
              "IPY_MODEL_ab2c47be04204fbf90414e1c70a4ae5a",
              "IPY_MODEL_b32dcce24fea4785bf28e59ed5fadd67"
            ],
            "layout": "IPY_MODEL_d246291589f8474081b775ee071ff43d"
          }
        },
        "2d6b038c670c464e8a99bc0514d09e26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35da65a608ea46eeb21b14673461cdff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2242655ff848a6ac0fb5b79490c5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d0058c1c9b4485798f0ab5e2e602ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9d23322d1d94e97a0c96e359e202948",
              "IPY_MODEL_4da84654896447cba4e07f2e1eb83ea9",
              "IPY_MODEL_dd25fa4cf59e436aa8944ab8bffb906e"
            ],
            "layout": "IPY_MODEL_176927173ef7470fa05403f4a6549454"
          }
        },
        "4da84654896447cba4e07f2e1eb83ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1402d0f1d9c34e51967ca08d63af374b",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdb819f2187a493fae732169679fbab7",
            "value": 32
          }
        },
        "518ebdb562e24b1387d383e179c9c832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b77e7b33fbd48e792b454fec2b5f697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5de1da4375574855b9055df7dfb21e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78cea82b488f4863b4d910fa7f258074",
              "IPY_MODEL_16f1c2646aef4fafa271284d06a3f011",
              "IPY_MODEL_b3fae5bf4c99431d8ad7d3ba32fa444b"
            ],
            "layout": "IPY_MODEL_ec68f7d85d1249738cbfcf46402cbf8f"
          }
        },
        "62805881f00541728b88f7bf7380eac7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b2132d1939464a9012d6c7c0740501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78cea82b488f4863b4d910fa7f258074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7f14f07a8414ab487c3e3ef09692b0d",
            "placeholder": "",
            "style": "IPY_MODEL_d420e05954734972bc27a74023c2b5a8",
            "value": "Evaluating:100%"
          }
        },
        "83949dc8b6024b618de2b1bc1149efab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "878d214690614956ad02649799a93f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d6b038c670c464e8a99bc0514d09e26",
            "placeholder": "",
            "style": "IPY_MODEL_4b2242655ff848a6ac0fb5b79490c5b4",
            "value": "32/32[00:21&lt;00:00,3.04s/it]"
          }
        },
        "8f7974757ddb4467aeebf2080e03f424": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd85f213c05443778d37c38f1e192167",
              "IPY_MODEL_0c1acb263c59433a8c732bf59736f8d6",
              "IPY_MODEL_878d214690614956ad02649799a93f12"
            ],
            "layout": "IPY_MODEL_05083ea7ec5143399ffcc4aadd9cec59"
          }
        },
        "9a16a65637cb4f27a0717d23aae1de91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8e9f0f0b1d4260a874bb455c964620": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6463af890bd49cfa34b13173f0100f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab2c47be04204fbf90414e1c70a4ae5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26c870b032e94f27bcf055b02b9b3245",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83949dc8b6024b618de2b1bc1149efab",
            "value": 32
          }
        },
        "b32dcce24fea4785bf28e59ed5fadd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d023352d8a7842b3a202f05e572df7aa",
            "placeholder": "",
            "style": "IPY_MODEL_518ebdb562e24b1387d383e179c9c832",
            "value": "32/32[00:18&lt;00:00,1.39s/it]"
          }
        },
        "b3fae5bf4c99431d8ad7d3ba32fa444b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c59b63390240ca8abdd83216f1661e",
            "placeholder": "",
            "style": "IPY_MODEL_5b77e7b33fbd48e792b454fec2b5f697",
            "value": "32/32[00:09&lt;00:00,2.57it/s]"
          }
        },
        "b7f14f07a8414ab487c3e3ef09692b0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9744cd4e0c43f7806df3762fc3e4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd85f213c05443778d37c38f1e192167": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f62f94dd9ef74594968e17b5456d1030",
            "placeholder": "",
            "style": "IPY_MODEL_e2127b51833247e6bece1b3bb26a2c7d",
            "value": "Evaluating:100%"
          }
        },
        "cdb819f2187a493fae732169679fbab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d023352d8a7842b3a202f05e572df7aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d246291589f8474081b775ee071ff43d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d420e05954734972bc27a74023c2b5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9d23322d1d94e97a0c96e359e202948": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71f41ffd91d42f6ba01aecd539d0e07",
            "placeholder": "",
            "style": "IPY_MODEL_67b2132d1939464a9012d6c7c0740501",
            "value": "Evaluating:100%"
          }
        },
        "dd25fa4cf59e436aa8944ab8bffb906e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35da65a608ea46eeb21b14673461cdff",
            "placeholder": "",
            "style": "IPY_MODEL_9f8e9f0f0b1d4260a874bb455c964620",
            "value": "32/32[00:07&lt;00:00,4.70it/s]"
          }
        },
        "e2127b51833247e6bece1b3bb26a2c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e71f41ffd91d42f6ba01aecd539d0e07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec68f7d85d1249738cbfcf46402cbf8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2809828843442cead54ccfdfb755a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f62f94dd9ef74594968e17b5456d1030": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66f35790b824658b569da013922a75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a16a65637cb4f27a0717d23aae1de91",
            "placeholder": "",
            "style": "IPY_MODEL_0189274652584d7cbbe325b5a0ee9a13",
            "value": "Evaluating:100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
